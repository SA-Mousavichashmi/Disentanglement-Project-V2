{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d610cc",
   "metadata": {},
   "source": [
    "# FactorVAE Model Testing Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f5ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reproducibility import set_deterministic_run, get_deterministic_dataloader\n",
    "\n",
    "seed = 42\n",
    "set_deterministic_run(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9663016",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b534592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils.visualize\n",
    "from trainers import UnsupervisedTrainer\n",
    "import losses\n",
    "import vae_models\n",
    "from datasets import get_dataset\n",
    "from utils.io import find_optimal_num_workers\n",
    "from metrics.utils import MetricAggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde2885d",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ddc0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- General Hyperparameters ---\n",
    "model_name = 'vae_locatello'  # Name of the model architecture file (e.g., 'vae_burgess')\n",
    "latent_dim = 10\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "rec_dist = 'bernoulli'  # Reconstruction distribution (e.g., 'bernoulli', 'gaussian')\n",
    "\n",
    "train_step_unit = 'epoch'  # Unit for training steps ('epoch' or 'iteration')\n",
    "num_train_steps = 5\n",
    "\n",
    "# train_step_unit = 'iteration'  # Unit for training steps ('epoch' or 'iteration')\n",
    "# num_train_steps = int(9e3)  # Number of training steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a257f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss Specific Hyperparameters ---\n",
    "# Factor VAE\n",
    "loss_name = 'factorvae'      # Type of loss\n",
    "loss_kwargs = {\n",
    "    'gamma': 6.4,          # Weight of the TC loss term\n",
    "    'discr_lr': 5e-5,      # Discriminator learning rate\n",
    "    'discr_betas': (0.5, 0.9), # Discriminator Adam betas\n",
    "    'rec_dist': rec_dist,\n",
    "    'device': device       # Pass device to loss for discriminator\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7d030",
   "metadata": {},
   "source": [
    "## 3. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a528c6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3D Shapes dataset with 480000 samples.\n"
     ]
    }
   ],
   "source": [
    "# Load 3D Shapes\n",
    "Shapes3D = get_dataset(\"shapes3d\")\n",
    "shapes3d_dataset = Shapes3D(selected_factors='all', not_selected_factors_index_value=None)\n",
    "# num_workers_3dshapes = find_optimal_num_workers(shapes3d_dataset, batch_size=batch_size, num_batches_to_test='all')\n",
    "num_workers_3dshapes = 4\n",
    "\n",
    "shapes3d_dataloader = get_deterministic_dataloader(dataset=shapes3d_dataset, \n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers_3dshapes,\n",
    "                                                   seed=seed,\n",
    "                                                   pin_memory=True)\n",
    "\n",
    "print(f\"Loaded 3D Shapes dataset with {len(shapes3d_dataset)} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19327e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dSprites dataset with 737280 samples.\n"
     ]
    }
   ],
   "source": [
    "# Load dSprites\n",
    "Dsprites = get_dataset('dsprites')\n",
    "\n",
    "dsprites_dataset = Dsprites(selected_factors='all', not_selected_factors_index_value=None)\n",
    "# num_workers_dsprites = find_optimal_num_workers(dsprites_dataset, batch_size=batch_size, num_batches_to_test='all')\n",
    "num_workers_dsprites = 7\n",
    "\n",
    "dsprites_dataloader = get_deterministic_dataloader(dataset=dsprites_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers_dsprites,\n",
    "                                                   seed=seed,\n",
    "                                                   pin_memory=True)\n",
    "\n",
    "print(f\"Loaded dSprites dataset with {len(dsprites_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f5d2d1",
   "metadata": {},
   "source": [
    "## 4. Setup Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cea16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_components(dataset, loss_kwargs):\n",
    "    \"\"\"Instantiates model, loss function, and optimizer based on config.\"\"\"\n",
    "    img_size = dataset[0][0].shape\n",
    "    n_data = len(dataset)\n",
    "    \n",
    "    # Instantiate Model\n",
    "    model = vae_models.select(name=model_name, img_size=img_size, latent_dim=latent_dim)\n",
    "\n",
    "    # FactorVAE loss needs the device for its internal discriminator\n",
    "    current_loss_kwargs = loss_kwargs.copy() # Avoid modifying the global dict\n",
    "    current_loss_kwargs['device'] = device\n",
    "    loss_fn = losses.select(loss_name, **current_loss_kwargs)\n",
    "\n",
    "    # Instantiate VAE Optimizer (Discriminator optimizer is inside the loss)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"--- Setup for {dataset.__class__.__name__} --- \")\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Loss: {loss_fn.__class__.__name__} (rec_dist={rec_dist}), kwargs={current_loss_kwargs}\")\n",
    "    print(f\"Optimizer (VAE): {optimizer.__class__.__name__}\")\n",
    "    print(f\"Optimizer (Disc): Adam (internal to loss)\")\n",
    "    print(f\"---------------------------\")\n",
    "\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded85e87",
   "metadata": {},
   "source": [
    "## 5. Train and Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a30c2",
   "metadata": {},
   "source": [
    "## 5.1 - 3D Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b13efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss kwargs specifically for 3D Shapes if needed, otherwise use global\n",
    "shapes3d_loss_kwargs = loss_kwargs.copy() # Start with global settings\n",
    "# shapes3d_loss_kwargs['gamma'] = 10 # Example: Override gamma for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fc8f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training on 3D Shapes =====\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m===== Training on 3D Shapes =====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model_3dshapes, loss_fn_3dshapes, optimizer_3dshapes \u001b[38;5;241m=\u001b[39m \u001b[43msetup_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes3d_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapes3d_loss_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Use BaseTrainer as FactorVAE loss handles optimization internally\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trainer_3dshapes \u001b[38;5;241m=\u001b[39m UnsupervisedTrainer(model\u001b[38;5;241m=\u001b[39mmodel_3dshapes,\n\u001b[1;32m      6\u001b[0m                                loss_fn\u001b[38;5;241m=\u001b[39mloss_fn_3dshapes,\n\u001b[1;32m      7\u001b[0m                                lr_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m                                log_loss_interval_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Log per epoch\u001b[39;00m\n\u001b[1;32m     13\u001b[0m                                )\n",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36msetup_components\u001b[0;34m(dataset, loss_kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m current_loss_kwargs \u001b[38;5;241m=\u001b[39m loss_kwargs\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;66;03m# Avoid modifying the global dict\u001b[39;00m\n\u001b[1;32m     11\u001b[0m current_loss_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m---> 12\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m \u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcurrent_loss_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Instantiate VAE Optimizer (Discriminator optimizer is inside the loss)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n",
      "File \u001b[0;32m/notebooks/losses/__init__.py:24\u001b[0m, in \u001b[0;36mselect\u001b[0;34m(name, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Loss(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfactorvae\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mn_vae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfactorvae\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Loss\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Loss(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetatcvae\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/notebooks/losses/n_vae/factorvae.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m baseloss\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialization\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreconstruction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reconstruction_loss\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkl_div\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kl_normal_loss\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Training on 3D Shapes =====\")\n",
    "model_3dshapes, loss_fn_3dshapes, optimizer_3dshapes = setup_components(shapes3d_dataset, shapes3d_loss_kwargs)\n",
    "\n",
    "# Use BaseTrainer as FactorVAE loss handles optimization internally\n",
    "trainer_3dshapes = UnsupervisedTrainer(model=model_3dshapes,\n",
    "                               loss_fn=loss_fn_3dshapes,\n",
    "                               lr_scheduler=None,\n",
    "                               optimizer=optimizer_3dshapes,\n",
    "                               device=device,\n",
    "                               train_step_unit=train_step_unit,\n",
    "                               return_log_loss=True, # Get logs back\n",
    "                               log_loss_interval_type='epoch' # Log per epoch\n",
    "                               )\n",
    "\n",
    "train_logs_3dshapes = trainer_3dshapes.train(shapes3d_dataloader, max_steps=num_train_steps)\n",
    "print(\"Training Logs (3D Shapes):\", train_logs_3dshapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Visualizing 3D Shapes Results =====\")\n",
    "visualizer_3dshapes = utils.visualize.Visualizer(vae_model=model_3dshapes, dataset=shapes3d_dataset)\n",
    "\n",
    "print(\"Plotting random reconstructions...\")\n",
    "visualizer_3dshapes.plot_random_reconstructions(10, mode='mean')\n",
    "plt.show()\n",
    "\n",
    "print(\"Plotting reconstructions from specific indices...\")\n",
    "indices_3dshapes = [5000, 6000, 7000, 100, 1000, 1024] # Example indices\n",
    "visualizer_3dshapes.plot_reconstructions_sub_dataset(indices_3dshapes, mode='mean')\n",
    "plt.show()\n",
    "\n",
    "print(\"Plotting latent traversals...\")\n",
    "visualizer_3dshapes.plot_all_latent_traversals(num_samples=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c788f8a",
   "metadata": {},
   "source": [
    "### 5.1.1 Metric Evaluation (3D Shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_compute = [\n",
    "    {'name': 'dci_d', 'args':{'num_train':5000, 'num_test':1000}},\n",
    "    {'name': 'mig', 'args':{}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_aggregator_3dshapes = MetricAggregator(metrics=metrics_to_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c14e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Computing Metrics for 3D Shapes =====\")\n",
    "metrics_results_3dshapes = metric_aggregator_3dshapes.compute(model=model_3dshapes, \n",
    "                                                              data_loader=shapes3d_dataloader, \n",
    "                                                              device=device)\n",
    "print(\"3D Shapes Metrics:\", metrics_results_3dshapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1895113",
   "metadata": {},
   "source": [
    "## 5.2. Train and Visualize: dSprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bdcbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss kwargs specifically for dSprites if needed, otherwise use global\n",
    "dsprites_loss_kwargs = loss_kwargs.copy() # Start with global settings\n",
    "# dsprites_loss_kwargs['gamma'] = 10 # Example: Override gamma for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Training on dSprites =====\")\n",
    "model_dsprites, loss_fn_dsprites, optimizer_dsprites = setup_components(dsprites_dataset, dsprites_loss_kwargs)\n",
    "\n",
    "# Use BaseTrainer as FactorVAE loss handles optimization internally\n",
    "trainer_dsprites = BaseTrainer(model=model_dsprites,\n",
    "                               loss_fn=loss_fn_dsprites,\n",
    "                               lr_scheduler=None,\n",
    "                               optimizer=optimizer_dsprites,\n",
    "                               device=device,\n",
    "                               train_step_unit=train_step_unit,\n",
    "                               return_log_loss=True, # Get logs back\n",
    "                               log_loss_interval_type='epoch' # Log per epoch\n",
    "                               )\n",
    "\n",
    "train_logs_dsprites = trainer_dsprites.train(dsprites_dataloader, max_steps=num_train_steps)\n",
    "print(\"Training Logs (dSprites):\", train_logs_dsprites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bfcdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Visualizing dSprites Results =====\")\n",
    "visualizer_dsprites = utils.visualize.Visualizer(vae_model=model_dsprites, dataset=dsprites_dataset)\n",
    "\n",
    "print(\"Plotting random reconstructions...\")\n",
    "visualizer_dsprites.plot_random_reconstructions(10, mode='mean')\n",
    "plt.show()\n",
    "\n",
    "print(\"Plotting reconstructions from specific indices...\")\n",
    "indices_dsprites = [0, 100000, 200000, 300000, 40000, 50000] # Example indices\n",
    "visualizer_dsprites.plot_reconstructions_sub_dataset(indices_dsprites, mode='mean')\n",
    "plt.show()\n",
    "\n",
    "print(\"Plotting latent traversals...\")\n",
    "visualizer_dsprites.plot_all_latent_traversals(num_samples=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66137985",
   "metadata": {},
   "source": [
    "### 5.2.1 Metric Evaluation (dSprites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_aggregator_dsprites = MetricAggregator(metrics=metrics_to_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7959179",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Computing Metrics for dSprites =====\")\n",
    "metrics_results_dsprites = metric_aggregator_dsprites.compute(model=model_dsprites, \n",
    "                                                            data_loader=dsprites_dataloader, \n",
    "                                                            device=device)\n",
    "print(\"dSprites Metrics:\", metrics_results_dsprites)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
