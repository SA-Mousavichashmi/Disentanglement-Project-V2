# Experiment configuration for running multiple seeds
# This file demonstrates experiment-based training with multiple random seeds

defaults:
  - base_config
  - dataset: dsprites
  - model: vae_burgess
  - loss: betavae
  - _self_

# Experiment settings
experiment_id: null  # Auto-generated if not specified
seeds: [42, 123, 456, 789, 999]  # List of random seeds to run
results_dir: "experiments"  # Base directory for experiment results
resume: true  # Resume interrupted experiments

# Trainer configuration
trainer:
  # Training settings
  step_unit: "epoch"
  max_steps: 50

  # Model settings  
  model:
    device: "auto"
    latent_dim: 10

  # Loss settings
  loss:
    beta: 4.0
    rec_dist: "bernoulli"

  # Optimizer settings
  optimizer:
    name: "Adam"
    lr: 1e-4
    weight_decay: 0.0

  # Learning rate scheduler (optional)
  lr_scheduler: null

  # Data loading
  dataloader:
    batch_size: 64
    num_workers: -1  # Auto-detect
    shuffle: true
    pin_memory: true

  # Progress tracking
  progress_bar:
    enabled: true
    log_iter_interval: 50

  # Logging settings
  logging:
    enabled: true
    return_logs: true
    loss_interval_type: "iter"
    loss_iter_interval: 100
    metrics_interval_type: "iter"
    metrics_iter_interval: 100

  # Checkpointing (will be automatically configured for each seed)
  checkpoint:
    enabled: true  # Will be overridden by experiment manager
    return_chkpt: false
    every_n_steps: null  # Only save final checkpoint
    step_type: "epoch"
    save_viz: false

  # Determinism (seed will be overridden for each run)
  determinism:
    use_cuda_det: true
    enforce_det: false

  # Performance optimization
  torch_compile:
    enabled: false
    mode: "max-autotune"
    backend: "inductor"
    fullgraph: false
    dynamic: false
