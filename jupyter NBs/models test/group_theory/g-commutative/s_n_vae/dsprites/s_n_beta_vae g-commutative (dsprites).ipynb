{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61845a43",
   "metadata": {},
   "source": [
    "# G-Commutative S-N-VAE Model Testing Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106968af",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters cell for papermill\n",
    "# This cell will be tagged as \"parameters\" to allow papermill to inject parameter values\n",
    "# Default seed value - can be overridden by papermill execution\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55671c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root: /workspace/Disentanglement-Project-V2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root by looking for .git or requirements.txt\n",
    "current = Path.cwd()\n",
    "while not any((current / marker).exists() for marker in ['.git', 'requirements.txt']):\n",
    "    if current.parent == current:\n",
    "        raise FileNotFoundError(\"Project root not found\")\n",
    "    current = current.parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "print(f\"Added project root: {current}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d13d7b",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d8ea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#### deterministic run ####\n",
    "determinism_kwargs = {\n",
    "    'seed': seed,  # Use parameterized seed value\n",
    "    'use_cuda_det': True,\n",
    "    'enforce_det':False,\n",
    "    'cublas_workspace_config': None,\n",
    "}\n",
    "\n",
    "##### Model parameters #####\n",
    "model_name = 's_n_vae_locatello'  # S-N-VAE model with Locatello architecture\n",
    "model_decoder_output_dist = 'bernoulli'  # Output distribution of the decoder\n",
    "\n",
    "# Define latent factor topologies: mix of Normal (R1) and Power Spherical (S1)\n",
    "latent_factor_topologies = ['S1', 'R1', 'R1']  # 3 factors total\n",
    "\n",
    "use_torch_compile = True  # Use torch.compile for model compilation\n",
    "\n",
    "#### Training parameters ####\n",
    "train_step_unit = 'epoch'  # Unit for training steps ('epoch' or 'iteration')\n",
    "num_train_steps = 300\n",
    "\n",
    "# train_step_unit = 'iteration'  # Unit for training steps ('epoch' or 'iteration')\n",
    "# num_train_steps = int(9e3)  # Number of training steps \n",
    "\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "\n",
    "#### losses ####\n",
    "loss_name = 'beta_s_n_vae'      # S-N-VAE Beta loss\n",
    "loss_kwargs_dsprites = {\n",
    "    'beta': 13,\n",
    "    'latent_factor_topologies': latent_factor_topologies,\n",
    "    'rec_dist': 'bernoulli',  # Reconstruction distribution\n",
    "    'log_kl_components': True,\n",
    "#     'schedulers_kwargs':[\n",
    "#     {\n",
    "#         'name': 'linear',\n",
    "#         'kwargs': {\n",
    "#             'param_name': 'beta',\n",
    "#             'initial_value': 0,\n",
    "#             'final_value': 16,\n",
    "#             'total_steps': 100000\n",
    "#         }\n",
    "#     }\n",
    "# ]\n",
    "}\n",
    "\n",
    "#### device parameters ####\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "### Checkpoint parameters ###\n",
    "return_chkpt = False\n",
    "chkpt_every_n_steps = 2400\n",
    "\n",
    "# chkpt_save_path = 'checkpoints/tests/test-epoch-1.pt'\n",
    "chkpt_save_path = None\n",
    "\n",
    "chkpt_save_dir = None\n",
    "# chkpt_save_dir = 'checkpoints/tests_s_n_vae'\n",
    "\n",
    "chkpt_save_master_dir = None\n",
    "chkpt_viz = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19743b",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1f42e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set deterministic run with kwargs: {'seed': 0, 'use_cuda_det': True, 'enforce_det': False, 'cublas_workspace_config': None}\n"
     ]
    }
   ],
   "source": [
    "if determinism_kwargs is not None:\n",
    "    # MUST Be set before importing any other modules\n",
    "    # to ensure reproducibility across all libraries\n",
    "    from utils.reproducibility import set_deterministic_run, get_deterministic_dataloader\n",
    "    set_deterministic_run(**determinism_kwargs)\n",
    "    print(f\"Set deterministic run with kwargs: {determinism_kwargs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c010a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3343ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils.visualize\n",
    "from trainers import UnsupervisedTrainer\n",
    "import losses\n",
    "import vae_models\n",
    "from datasets import get_dataset\n",
    "from utils.io import find_optimal_num_workers\n",
    "from metrics.utils import MetricAggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f46c2",
   "metadata": {},
   "source": [
    "# Dataset Setup and G-Commutative Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8cda39",
   "metadata": {},
   "source": [
    "# dSprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead6fa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 18.4M  100 18.4M    0     0  8048k      0  0:00:02  0:00:02 --:--:-- 28.2M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dSprites dataset with 40960 samples.\n"
     ]
    }
   ],
   "source": [
    "# Load dSprites\n",
    "Dsprites = get_dataset('dsprites')\n",
    "\n",
    "# dsprites_dataset = Dsprites(selected_factors='all', not_selected_factors_index_value=None)\n",
    "dsprites_dataset = Dsprites(selected_factors=['posX', 'posY', 'orientation'], not_selected_factors_index_value={'scale':5, 'shape':0, 'color':0})\n",
    "\n",
    "# num_workers_dsprites = find_optimal_num_workers(dsprites_dataset, batch_size=batch_size, num_batches_to_test='all')\n",
    "num_workers_dsprites = 7\n",
    "\n",
    "if determinism_kwargs is not None:\n",
    "    dsprites_dataloader = get_deterministic_dataloader(dataset=dsprites_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers_dsprites,\n",
    "                                                   seed=seed,  # Use parameterized seed value\n",
    "                                                   pin_memory=True)\n",
    "else:\n",
    "    dsprites_dataloader = torch.utils.data.DataLoader(dsprites_dataset, \n",
    "                                                      batch_size=batch_size, \n",
    "                                                      num_workers=num_workers_dsprites, \n",
    "                                                      shuffle=True, \n",
    "                                                      pin_memory=True)\n",
    "\n",
    "print(f\"Loaded dSprites dataset with {len(dsprites_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d31c8",
   "metadata": {},
   "source": [
    "# G-Commutative VAE Implementation\n",
    "\n",
    "This notebook implements and tests the **G-Commutative S-N-VAE** model with Group Theory constraints. The G-Commutative VAE extends the standard S-N-VAE by adding commutative constraints that enforce structured relationships in the latent space.\n",
    "\n",
    "## Model Architecture\n",
    "- **Base Model**: S-N-VAE with Locatello encoder/decoder architecture\n",
    "- **Latent Space**: Mixed topology with ['S1', 'R1', 'R1'] factors\n",
    "- **Group Theory Extensions**: Commutative constraints enforcing g‚àòg' = g'‚àòg\n",
    "\n",
    "## Key Features\n",
    "- üîÑ **Commutative Constraints**: Enforces commutativity properties in latent transformations\n",
    "- üìà **Progressive Training**: Gradual increase of constraint strength with warm-up period\n",
    "- üéØ **Group Actions**: Supports R¬π (translation) and S¬π (rotation) transformations\n",
    "- ‚öñÔ∏è **Balanced Loss**: Combines reconstruction loss with group theory constraints\n",
    "\n",
    "## Training Strategy\n",
    "- **Warm-up Phase**: Initial 5000 steps focus on reconstruction to stabilize training\n",
    "- **Progressive Weighting**: Commutative loss weight increases from 0.05 to 10.0 over training\n",
    "- **Deterministic Training**: Fixed seed for reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9916e",
   "metadata": {},
   "source": [
    "# G-Commutative Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687e370c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING SETTINGS COMPARISON ===\n",
      "Standard S-N-VAE vs G-Commutative S-N-VAE:\n",
      "‚úì Model architecture: IDENTICAL (s_n_vae_locatello)\n",
      "‚úì Decoder output dist: IDENTICAL (bernoulli)\n",
      "‚úì Latent topologies: IDENTICAL (['S1', 'R1', 'R1'])\n",
      "‚úì Learning rate: IDENTICAL (0.0001)\n",
      "‚úì Batch size: IDENTICAL (64)\n",
      "‚úì Training steps: IDENTICAL (300 epochs)\n",
      "‚úì Base loss: IDENTICAL (beta_s_n_vae with bernoulli)\n",
      "‚úì Base loss params: IDENTICAL (beta=13)\n",
      "+ ADDITIONAL: Group theory commutative constraints (weight=1.0)\n",
      "+ ADDITIONAL: Warm-up period (5000 steps)\n",
      "üîß FIXED: Using correct loss name 'group_theory_snvae' for S-N-VAE\n",
      "\n",
      "‚Üí This ensures fair comparison: same base training + group constraints\n"
     ]
    }
   ],
   "source": [
    "#### G-Commutative Loss Configuration ####\n",
    "# DESIGN PHILOSOPHY: Keep ALL basic training settings identical to standard S-N-VAE\n",
    "# The ONLY difference is the addition of group theory constraints on top of the base loss\n",
    "\n",
    "# FIXED: Use correct loss name for S-N-VAE group theory\n",
    "g_commutative_loss_name = 'group_theory_snvae'  # S-N-VAE compatible group theory loss\n",
    "\n",
    "# Base loss configuration - use EXACT same settings as standard S-N-VAE\n",
    "base_loss_g_commutative = {\n",
    "    'name': 'beta_s_n_vae',\n",
    "    'kwargs': loss_kwargs_dsprites  # Identical to standard S-N-VAE settings\n",
    "}\n",
    "\n",
    "# Group Theory Loss Parameters for G-Commutative\n",
    "loss_kwargs_g_commutative = {\n",
    "    'base_loss_name': base_loss_g_commutative['name'],\n",
    "    'base_loss_kwargs': base_loss_g_commutative['kwargs'],\n",
    "    'latent_factor_topologies': latent_factor_topologies,\n",
    "    'device': device,  # FIXED: Required parameter\n",
    "    \n",
    "    # KEEP IDENTICAL: Same reconstruction distribution as standard S-N-VAE\n",
    "    'rec_dist': 'bernoulli',  # Same as standard S-N-VAE for fair comparison\n",
    "    \n",
    "    ### ADDED GROUP THEORY CONSTRAINTS (only difference) ###\n",
    "    'commutative_weight': 1.0,                    # Enable commutative loss\n",
    "    'commutative_component_order': 2,             # Use pairs for commutative operations\n",
    "    'commutative_comparison_dist': 'gaussian',    # Comparison metric for commutative constraints\n",
    "    \n",
    "    ### Meaningful settings (disabled for pure g-commutative) ###\n",
    "    'meaningful_weight': 0.0,                     # Disable meaningful loss for pure commutative\n",
    "    'meaningful_component_order': 1,\n",
    "    'meaningful_transformation_order': 1,\n",
    "    'meaningful_critic_gradient_penalty_weight': 10.0,  # FIXED: Required parameter (even if not used)\n",
    "    'meaningful_critic_lr': 1e-4,                 # FIXED: Required parameter (even if not used)\n",
    "    'meaningful_n_critic': 1,\n",
    "    \n",
    "    ### Group theory general settings ###\n",
    "    'deterministic_rep': True,                    # Use deterministic representations  \n",
    "    'g_action_r1_range': 2.0,                    # Range for R1 (translation) actions\n",
    "    'g_action_s1_range': 2 * torch.pi,           # Full rotation range for S1 actions\n",
    "    'g_action_r1_dist': 'uniform',               # Distribution for R1 action sampling\n",
    "    'g_action_s1_dist': 'uniform',               # Distribution for S1 action sampling\n",
    "    'comp_latent_select_threshold': 0.1,         # Threshold for selecting latent components\n",
    "    'warm_up_steps': 5000,                       # Warm-up steps before applying group losses\n",
    "    \n",
    "    ### Learning rate scheduling ###\n",
    "    'schedulers_kwargs': [\n",
    "        {\n",
    "            'name': 'linear',\n",
    "            'kwargs': {\n",
    "                'param_name': 'commutative_weight',\n",
    "                'initial_value': 0.05,           # Start with low commutative weight\n",
    "                'final_value': 10.0,             # Gradually increase to strong constraint\n",
    "                'before_start_value': 0,\n",
    "                'start_step': 5000,              # Start scheduling after warm-up\n",
    "                'total_steps': 192000 - 5000  # Schedule over remaining training steps\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=== TRAINING SETTINGS COMPARISON ===\")\n",
    "print(\"Standard S-N-VAE vs G-Commutative S-N-VAE:\")\n",
    "print(f\"‚úì Model architecture: IDENTICAL ({model_name})\")\n",
    "print(f\"‚úì Decoder output dist: IDENTICAL ({model_decoder_output_dist})\")\n",
    "print(f\"‚úì Latent topologies: IDENTICAL ({latent_factor_topologies})\")\n",
    "print(f\"‚úì Learning rate: IDENTICAL ({learning_rate})\")\n",
    "print(f\"‚úì Batch size: IDENTICAL ({batch_size})\")\n",
    "print(f\"‚úì Training steps: IDENTICAL ({num_train_steps} {train_step_unit}s)\")\n",
    "print(f\"‚úì Base loss: IDENTICAL ({base_loss_g_commutative['name']} with bernoulli)\")\n",
    "print(f\"‚úì Base loss params: IDENTICAL (beta={loss_kwargs_dsprites['beta']})\")\n",
    "print(f\"+ ADDITIONAL: Group theory commutative constraints (weight={loss_kwargs_g_commutative['commutative_weight']})\")\n",
    "print(f\"+ ADDITIONAL: Warm-up period ({loss_kwargs_g_commutative['warm_up_steps']} steps)\")\n",
    "print(f\"üîß FIXED: Using correct loss name '{g_commutative_loss_name}' for S-N-VAE\")\n",
    "print(\"\\n‚Üí This ensures fair comparison: same base training + group constraints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ea9b9",
   "metadata": {},
   "source": [
    "## Setup Model, Loss, and Optimizer for G-Commutative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bdc0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_g_commutative_components(dataset, loss_kwargs, latent_factor_topologies):\n",
    "    \"\"\"Instantiates model, group theory loss function, and optimizer for g-commutative training.\"\"\"\n",
    "    img_size = dataset[0][0].shape\n",
    "    n_data = len(dataset)\n",
    "    \n",
    "    # Instantiate S-N-VAE Model (same as before - the model architecture doesn't change)\n",
    "    model = vae_models.select(name=model_name, \n",
    "                              img_size=img_size, \n",
    "                              latent_factor_topologies=latent_factor_topologies,\n",
    "                              decoder_output_dist=model_decoder_output_dist\n",
    "                              ).to(device)\n",
    "\n",
    "    # Instantiate Group Theory Loss with G-Commutative constraints\n",
    "    loss_fn = losses.select(g_commutative_loss_name, **loss_kwargs)\n",
    "\n",
    "    # Instantiate Optimizer (same as before)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"--- G-Commutative Setup for {dataset.__class__.__name__} --- \")\n",
    "    print(f\"Model: {model.model_name}\")\n",
    "    print(f\"Latent factor topologies: {latent_factor_topologies}\")\n",
    "    print(f\"Loss: {loss_fn.name}\")\n",
    "    print(f\"  ‚Ü≥ Base loss: {loss_kwargs['base_loss_name']}\")\n",
    "    print(f\"  ‚Ü≥ Commutative weight: {loss_kwargs['commutative_weight']}\")\n",
    "    print(f\"  ‚Ü≥ Meaningful weight: {loss_kwargs['meaningful_weight']}\")\n",
    "    print(f\"  ‚Ü≥ Reconstruction dist: {loss_kwargs['rec_dist']}\")\n",
    "    print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eef7ef",
   "metadata": {},
   "source": [
    "## Train G-Commutative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e0c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training G-Commutative S-N-VAE on dSprites =====\n",
      "--- G-Commutative Setup for DSprites --- \n",
      "Model: s_n_vae_locatello\n",
      "Latent factor topologies: ['S1', 'R1', 'R1']\n",
      "Loss: group_theory_s_n_vae\n",
      "  ‚Ü≥ Base loss: beta_s_n_vae\n",
      "  ‚Ü≥ Commutative weight: 1.0\n",
      "  ‚Ü≥ Meaningful weight: 0.0\n",
      "  ‚Ü≥ Reconstruction dist: bernoulli\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.0001\n",
      "\n",
      "Starting G-Commutative training for 300 epochs...\n",
      "Note: Group losses will be applied after 5000 warm-up steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training for 192000 iter, 300.00 epochs:   9%|‚ñâ         | 18033/192000 [06:07<1:17:39, 37.33it/s, epoch=28.12/300.00, g_commutative_loss=5.44, iter=18000/192000, kl_loss=6.12, kl_loss_0_S1=0.801, kl_loss_1_R1=2.79, kl_loss_2_R1=2.52, loss=241, rec_loss=157, sched_commutative_weight=0.742]"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Training G-Commutative S-N-VAE on dSprites =====\")\n",
    "model_g_comm_dsprites, loss_fn_g_comm_dsprites, optimizer_g_comm_dsprites = setup_g_commutative_components(\n",
    "    dsprites_dataset, \n",
    "    loss_kwargs_g_commutative,\n",
    "    latent_factor_topologies\n",
    ")\n",
    "\n",
    "# Setup trainer for G-Commutative model\n",
    "trainer_g_comm_dsprites = UnsupervisedTrainer(model=model_g_comm_dsprites,\n",
    "                                             loss=loss_fn_g_comm_dsprites,\n",
    "                                             optimizer=optimizer_g_comm_dsprites,\n",
    "                                             lr_scheduler=None,\n",
    "                                             determinism_kwargs=determinism_kwargs,\n",
    "                                             use_torch_compile=use_torch_compile,\n",
    "                                             return_logs=True,\n",
    "                                             return_chkpt=return_chkpt,\n",
    "                                             chkpt_save_path=chkpt_save_path,\n",
    "                                             chkpt_save_dir=chkpt_save_dir,\n",
    "                                             chkpt_every_n_steps=chkpt_every_n_steps,\n",
    "                                             chkpt_viz=chkpt_viz\n",
    "                                             )\n",
    "\n",
    "# Train the G-Commutative model\n",
    "print(f\"\\nStarting G-Commutative training for {num_train_steps} {train_step_unit}s...\")\n",
    "print(f\"Note: Group losses will be applied after {loss_kwargs_g_commutative['warm_up_steps']} warm-up steps\")\n",
    "trainer_g_comm_dsprites.train(max_steps=num_train_steps, step_unit=train_step_unit, dataloader=dsprites_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e579552",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Visualizing G-Commutative dSprites Results =====\")\n",
    "visualizer_g_comm_dsprites = utils.visualize.SNVAEVisualizer(vae_model=model_g_comm_dsprites, dataset=dsprites_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41688d96",
   "metadata": {},
   "source": [
    "# Results Visualization and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202a711",
   "metadata": {},
   "source": [
    "## Model Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9439949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting random reconstructions...\")\n",
    "visualizer_g_comm_dsprites.plot_random_reconstructions(10, mode='mean')\n",
    "plt.show()\n",
    "\n",
    "print(\"Plotting reconstructions from specific indices...\")\n",
    "indices_dsprites = [0, 10, 20, 30, 40, 50]  # Example indices\n",
    "visualizer_g_comm_dsprites.plot_reconstructions_sub_dataset(indices_dsprites, mode='mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34580b0d",
   "metadata": {},
   "source": [
    "## Latent Space Traversals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc24ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting latent traversals...\")\n",
    "visualizer_g_comm_dsprites.plot_all_latent_traversals(num_samples=15,\n",
    "                                                      r1_max_traversal_type='probability',\n",
    "                                                      r1_max_traversal=0.95,\n",
    "                                                      s1_max_traversal_type='fraction',\n",
    "                                                      s1_max_traversal=1.0,\n",
    "                                                      use_ref_img=True\n",
    "                                                      )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a reference image index for detailed analysis\n",
    "ref_img_idx_dsprites = 495  # Example index\n",
    "ref_img_dsprites = dsprites_dataset[ref_img_idx_dsprites][0]\n",
    "\n",
    "# Plot the reference image\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(ref_img_dsprites.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
    "plt.title(f\"Reference Image for Analysis (Index: {ref_img_idx_dsprites})\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Single latent traversal analysis\n",
    "latent_factor_idx = 0  # Index of the latent dimension to traverse\n",
    "print(f\"Plotting single latent traversal for dimension {latent_factor_idx}...\")\n",
    "visualizer_g_comm_dsprites.plot_single_latent_traversal(latent_factor_idx, \n",
    "                                                        ref_img=ref_img_dsprites, \n",
    "                                                        num_samples=11,\n",
    "                                                        max_traversal_type='fraction',\n",
    "                                                        max_traversal=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb032cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete latent traversal analysis using the reference image\n",
    "print(\"Plotting all latent traversals based on reference image...\")\n",
    "visualizer_g_comm_dsprites.plot_all_latent_traversals(ref_img=ref_img_dsprites, \n",
    "                                                      num_samples=15,\n",
    "                                                      r1_max_traversal_type='probability',\n",
    "                                                      r1_max_traversal=0.95,\n",
    "                                                      s1_max_traversal_type='fraction',\n",
    "                                                      s1_max_traversal=1\n",
    "                                                      )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
