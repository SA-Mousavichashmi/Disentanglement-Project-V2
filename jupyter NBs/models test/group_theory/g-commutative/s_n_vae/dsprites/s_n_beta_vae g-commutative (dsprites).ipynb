{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61845a43",
   "metadata": {},
   "source": [
    "# G-Commutative S-N-VAE Model Testing Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106968af",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters cell for papermill\n",
    "# This cell will be tagged as \"parameters\" to allow papermill to inject parameter values\n",
    "# Default seed value - can be overridden by papermill execution\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55671c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root: /workspace/Disentanglement-Project-V2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root by looking for .git or requirements.txt\n",
    "current = Path.cwd()\n",
    "while not any((current / marker).exists() for marker in ['.git', 'requirements.txt']):\n",
    "    if current.parent == current:\n",
    "        raise FileNotFoundError(\"Project root not found\")\n",
    "    current = current.parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "print(f\"Added project root: {current}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d13d7b",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8ea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#### deterministic run ####\n",
    "determinism_kwargs = {\n",
    "    'seed': seed,  # Use parameterized seed value\n",
    "    'use_cuda_det': True,\n",
    "    'enforce_det':False,\n",
    "    'cublas_workspace_config': None,\n",
    "}\n",
    "\n",
    "##### Model parameters #####\n",
    "model_name = 's_n_vae_locatello'  # S-N-VAE model with Locatello architecture\n",
    "model_decoder_output_dist = 'bernoulli'  # Output distribution of the decoder\n",
    "\n",
    "# Define latent factor topologies: mix of Normal (R1) and Power Spherical (S1)\n",
    "latent_factor_topologies = ['S1', 'R1', 'R1']  # 3 factors total\n",
    "\n",
    "use_torch_compile = True  # Use torch.compile for model compilation\n",
    "\n",
    "#### Training parameters ####\n",
    "train_step_unit = 'epoch'  # Unit for training steps ('epoch' or 'iteration')\n",
    "num_train_steps = 300\n",
    "\n",
    "# train_step_unit = 'iteration'  # Unit for training steps ('epoch' or 'iteration')\n",
    "# num_train_steps = int(9e3)  # Number of training steps \n",
    "\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "\n",
    "#### losses ####\n",
    "loss_name = 'beta_s_n_vae'      # S-N-VAE Beta loss\n",
    "loss_kwargs_dsprites = {\n",
    "    'beta': 13,\n",
    "    'latent_factor_topologies': latent_factor_topologies,\n",
    "    'rec_dist': 'bernoulli',  # Reconstruction distribution\n",
    "    'log_kl_components': True,\n",
    "#     'schedulers_kwargs':[\n",
    "#     {\n",
    "#         'name': 'linear',\n",
    "#         'kwargs': {\n",
    "#             'param_name': 'beta',\n",
    "#             'initial_value': 0,\n",
    "#             'final_value': 16,\n",
    "#             'total_steps': 100000\n",
    "#         }\n",
    "#     }\n",
    "# ]\n",
    "}\n",
    "\n",
    "#### device parameters ####\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "### Checkpoint parameters ###\n",
    "return_chkpt = False\n",
    "chkpt_every_n_steps = 2400\n",
    "\n",
    "# chkpt_save_path = 'checkpoints/tests/test-epoch-1.pt'\n",
    "chkpt_save_path = None\n",
    "\n",
    "chkpt_save_dir = None\n",
    "# chkpt_save_dir = 'checkpoints/tests_s_n_vae'\n",
    "\n",
    "chkpt_save_master_dir = None\n",
    "chkpt_viz = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19743b",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1f42e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set deterministic run with kwargs: {'seed': 5, 'use_cuda_det': True, 'enforce_det': False, 'cublas_workspace_config': None}\n"
     ]
    }
   ],
   "source": [
    "if determinism_kwargs is not None:\n",
    "    # MUST Be set before importing any other modules\n",
    "    # to ensure reproducibility across all libraries\n",
    "    from utils.reproducibility import set_deterministic_run, get_deterministic_dataloader\n",
    "    set_deterministic_run(**determinism_kwargs)\n",
    "    print(f\"Set deterministic run with kwargs: {determinism_kwargs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c010a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3343ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils.visualize\n",
    "from trainers import UnsupervisedTrainer\n",
    "import losses\n",
    "import vae_models\n",
    "from datasets import get_dataset\n",
    "from utils.io import find_optimal_num_workers\n",
    "from metrics.utils import MetricAggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f46c2",
   "metadata": {},
   "source": [
    "# Dataset Setup and G-Commutative Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8cda39",
   "metadata": {},
   "source": [
    "# dSprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6fa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dSprites dataset with 40960 samples.\n"
     ]
    }
   ],
   "source": [
    "# Load dSprites\n",
    "Dsprites = get_dataset('dsprites')\n",
    "\n",
    "# dsprites_dataset = Dsprites(selected_factors='all', not_selected_factors_index_value=None)\n",
    "dsprites_dataset = Dsprites(selected_factors=['posX', 'posY', 'orientation'], not_selected_factors_index_value={'scale':5, 'shape':0, 'color':0})\n",
    "\n",
    "# num_workers_dsprites = find_optimal_num_workers(dsprites_dataset, batch_size=batch_size, num_batches_to_test='all')\n",
    "num_workers_dsprites = 7\n",
    "\n",
    "if determinism_kwargs is not None:\n",
    "    dsprites_dataloader = get_deterministic_dataloader(dataset=dsprites_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers_dsprites,\n",
    "                                                   seed=seed,  # Use parameterized seed value\n",
    "                                                   pin_memory=True)\n",
    "else:\n",
    "    dsprites_dataloader = torch.utils.data.DataLoader(dsprites_dataset, \n",
    "                                                      batch_size=batch_size, \n",
    "                                                      num_workers=num_workers_dsprites, \n",
    "                                                      shuffle=True, \n",
    "                                                      pin_memory=True)\n",
    "\n",
    "print(f\"Loaded dSprites dataset with {len(dsprites_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d31c8",
   "metadata": {},
   "source": [
    "# G-Commutative VAE Implementation\n",
    "\n",
    "This notebook implements and tests the **G-Commutative S-N-VAE** model with Group Theory constraints. The G-Commutative VAE extends the standard S-N-VAE by adding commutative constraints that enforce structured relationships in the latent space.\n",
    "\n",
    "## Model Architecture\n",
    "- **Base Model**: S-N-VAE with Locatello encoder/decoder architecture\n",
    "- **Latent Space**: Mixed topology with ['S1', 'R1', 'R1'] factors\n",
    "- **Group Theory Extensions**: Commutative constraints enforcing gâˆ˜g' = g'âˆ˜g\n",
    "\n",
    "## Key Features\n",
    "- ðŸ”„ **Commutative Constraints**: Enforces commutativity properties in latent transformations\n",
    "- ðŸ“ˆ **Progressive Training**: Gradual increase of constraint strength with warm-up period\n",
    "- ðŸŽ¯ **Group Actions**: Supports RÂ¹ (translation) and SÂ¹ (rotation) transformations\n",
    "- âš–ï¸ **Balanced Loss**: Combines reconstruction loss with group theory constraints\n",
    "\n",
    "## Training Strategy\n",
    "- **Warm-up Phase**: Initial 5000 steps focus on reconstruction to stabilize training\n",
    "- **Progressive Weighting**: Commutative loss weight increases from 0.05 to 10.0 over training\n",
    "- **Deterministic Training**: Fixed seed for reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9916e",
   "metadata": {},
   "source": [
    "# G-Commutative Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e370c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING SETTINGS COMPARISON ===\n",
      "Standard S-N-VAE vs G-Commutative S-N-VAE:\n",
      "âœ“ Model architecture: IDENTICAL (s_n_vae_locatello)\n",
      "âœ“ Decoder output dist: IDENTICAL (bernoulli)\n",
      "âœ“ Latent topologies: IDENTICAL (['S1', 'R1', 'R1'])\n",
      "âœ“ Learning rate: IDENTICAL (0.0001)\n",
      "âœ“ Batch size: IDENTICAL (64)\n",
      "âœ“ Training steps: IDENTICAL (300 epochs)\n",
      "âœ“ Base loss: IDENTICAL (beta_s_n_vae with bernoulli)\n",
      "âœ“ Base loss params: IDENTICAL (beta=12)\n",
      "+ ADDITIONAL: Group theory commutative constraints (weight=1.0)\n",
      "+ ADDITIONAL: Warm-up period (5000 steps)\n",
      "ðŸ”§ FIXED: Using correct loss name 'group_theory_snvae' for S-N-VAE\n",
      "\n",
      "â†’ This ensures fair comparison: same base training + group constraints\n"
     ]
    }
   ],
   "source": [
    "#### G-Commutative Loss Configuration ####\n",
    "# DESIGN PHILOSOPHY: Keep ALL basic training settings identical to standard S-N-VAE\n",
    "# The ONLY difference is the addition of group theory constraints on top of the base loss\n",
    "\n",
    "# FIXED: Use correct loss name for S-N-VAE group theory\n",
    "g_commutative_loss_name = 'group_theory_snvae'  # S-N-VAE compatible group theory loss\n",
    "\n",
    "# Base loss configuration - use EXACT same settings as standard S-N-VAE\n",
    "base_loss_g_commutative = {\n",
    "    'name': 'beta_s_n_vae',\n",
    "    'kwargs': loss_kwargs_dsprites  # Identical to standard S-N-VAE settings\n",
    "}\n",
    "\n",
    "# Group Theory Loss Parameters for G-Commutative\n",
    "loss_kwargs_g_commutative = {\n",
    "    'base_loss_name': base_loss_g_commutative['name'],\n",
    "    'base_loss_kwargs': base_loss_g_commutative['kwargs'],\n",
    "    'latent_factor_topologies': latent_factor_topologies,\n",
    "    'device': device,  # FIXED: Required parameter\n",
    "    \n",
    "    # KEEP IDENTICAL: Same reconstruction distribution as standard S-N-VAE\n",
    "    'rec_dist': 'bernoulli',  # Same as standard S-N-VAE for fair comparison\n",
    "    \n",
    "    ### ADDED GROUP THEORY CONSTRAINTS (only difference) ###\n",
    "    'commutative_weight': 1.0,                    # Enable commutative loss\n",
    "    'commutative_component_order': 2,             # Use pairs for commutative operations\n",
    "    'commutative_comparison_dist': 'gaussian',    # Comparison metric for commutative constraints\n",
    "    \n",
    "    ### Meaningful settings (disabled for pure g-commutative) ###\n",
    "    'meaningful_weight': 0.0,                     # Disable meaningful loss for pure commutative\n",
    "    'meaningful_component_order': 1,\n",
    "    'meaningful_transformation_order': 1,\n",
    "    'meaningful_critic_gradient_penalty_weight': 10.0,  # FIXED: Required parameter (even if not used)\n",
    "    'meaningful_critic_lr': 1e-4,                 # FIXED: Required parameter (even if not used)\n",
    "    'meaningful_n_critic': 1,\n",
    "    \n",
    "    ### Group theory general settings ###\n",
    "    'deterministic_rep': True,                    # Use deterministic representations  \n",
    "    'g_action_r1_range': 2.0,                    # Range for R1 (translation) actions\n",
    "    'g_action_s1_range': 2 * torch.pi,           # Full rotation range for S1 actions\n",
    "    'g_action_r1_dist': 'uniform',               # Distribution for R1 action sampling\n",
    "    'g_action_s1_dist': 'uniform',               # Distribution for S1 action sampling\n",
    "    'comp_latent_select_threshold': 0.1,         # Threshold for selecting latent components\n",
    "    'warm_up_steps': 5000,                       # Warm-up steps before applying group losses\n",
    "    \n",
    "    ### Learning rate scheduling ###\n",
    "    'schedulers_kwargs': [\n",
    "        {\n",
    "            'name': 'linear',\n",
    "            'kwargs': {\n",
    "                'param_name': 'commutative_weight',\n",
    "                'initial_value': 0.05,           # Start with low commutative weight\n",
    "                'final_value': 10.0,             # Gradually increase to strong constraint\n",
    "                'before_start_value': 0,\n",
    "                'start_step': 5000,              # Start scheduling after warm-up\n",
    "                'total_steps': int(num_train_steps * 0.8 if train_step_unit == 'epoch' \n",
    "                                 else num_train_steps * 0.8)  # Schedule over 80% of training\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=== TRAINING SETTINGS COMPARISON ===\")\n",
    "print(\"Standard S-N-VAE vs G-Commutative S-N-VAE:\")\n",
    "print(f\"âœ“ Model architecture: IDENTICAL ({model_name})\")\n",
    "print(f\"âœ“ Decoder output dist: IDENTICAL ({model_decoder_output_dist})\")\n",
    "print(f\"âœ“ Latent topologies: IDENTICAL ({latent_factor_topologies})\")\n",
    "print(f\"âœ“ Learning rate: IDENTICAL ({learning_rate})\")\n",
    "print(f\"âœ“ Batch size: IDENTICAL ({batch_size})\")\n",
    "print(f\"âœ“ Training steps: IDENTICAL ({num_train_steps} {train_step_unit}s)\")\n",
    "print(f\"âœ“ Base loss: IDENTICAL ({base_loss_g_commutative['name']} with bernoulli)\")\n",
    "print(f\"âœ“ Base loss params: IDENTICAL (beta={loss_kwargs_dsprites['beta']})\")\n",
    "print(f\"+ ADDITIONAL: Group theory commutative constraints (weight={loss_kwargs_g_commutative['commutative_weight']})\")\n",
    "print(f\"+ ADDITIONAL: Warm-up period ({loss_kwargs_g_commutative['warm_up_steps']} steps)\")\n",
    "print(f\"ðŸ”§ FIXED: Using correct loss name '{g_commutative_loss_name}' for S-N-VAE\")\n",
    "print(\"\\nâ†’ This ensures fair comparison: same base training + group constraints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ea9b9",
   "metadata": {},
   "source": [
    "## Setup Model, Loss, and Optimizer for G-Commutative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_g_commutative_components(dataset, loss_kwargs, latent_factor_topologies):\n",
    "    \"\"\"Instantiates model, group theory loss function, and optimizer for g-commutative training.\"\"\"\n",
    "    img_size = dataset[0][0].shape\n",
    "    n_data = len(dataset)\n",
    "    \n",
    "    # Instantiate S-N-VAE Model (same as before - the model architecture doesn't change)\n",
    "    model = vae_models.select(name=model_name, \n",
    "                              img_size=img_size, \n",
    "                              latent_factor_topologies=latent_factor_topologies,\n",
    "                              decoder_output_dist=model_decoder_output_dist\n",
    "                              ).to(device)\n",
    "\n",
    "    # Instantiate Group Theory Loss with G-Commutative constraints\n",
    "    loss_fn = losses.select(g_commutative_loss_name, **loss_kwargs)\n",
    "\n",
    "    # Instantiate Optimizer (same as before)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"--- G-Commutative Setup for {dataset.__class__.__name__} --- \")\n",
    "    print(f\"Model: {model.model_name}\")\n",
    "    print(f\"Latent factor topologies: {latent_factor_topologies}\")\n",
    "    print(f\"Loss: {loss_fn.name}\")\n",
    "    print(f\"  â†³ Base loss: {loss_kwargs['base_loss_name']}\")\n",
    "    print(f\"  â†³ Commutative weight: {loss_kwargs['commutative_weight']}\")\n",
    "    print(f\"  â†³ Meaningful weight: {loss_kwargs['meaningful_weight']}\")\n",
    "    print(f\"  â†³ Reconstruction dist: {loss_kwargs['rec_dist']}\")\n",
    "    print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eef7ef",
   "metadata": {},
   "source": [
    "## Train G-Commutative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e0c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training G-Commutative S-N-VAE on dSprites =====\n",
      "--- G-Commutative Setup for DSprites --- \n",
      "Model: s_n_vae_locatello\n",
      "Latent factor topologies: ['S1', 'R1', 'R1']\n",
      "Loss: group_theory_s_n_vae\n",
      "  â†³ Base loss: beta_s_n_vae\n",
      "  â†³ Commutative weight: 1.0\n",
      "  â†³ Meaningful weight: 0.0\n",
      "  â†³ Reconstruction dist: bernoulli\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.0001\n",
      "\n",
      "Starting G-Commutative training for 300 epochs...\n",
      "Note: Group losses will be applied after 5000 warm-up steps\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 5754, 5755, 5756, 5757, 5758, 5759, 5760) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/torchdata/stateful_dataloader/stateful_dataloader.py:1215\u001b[0m, in \u001b[0;36m_StatefulMultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1215\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting G-Commutative training for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_train_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_step_unit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote: Group losses will be applied after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_kwargs_g_commutative[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarm_up_steps\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m warm-up steps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mtrainer_g_comm_dsprites\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_step_unit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdsprites_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/Disentanglement-Project-V2/trainers/basetrainer.py:316\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self, step_unit, max_steps, dataloader)\u001b[0m\n\u001b[1;32m    313\u001b[0m current_interval_logs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    314\u001b[0m epoch_accumulated_logs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m) \u001b[38;5;66;03m# Accumulates logs for the current epoch\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m approx_epochs \u001b[38;5;241m=\u001b[39m total_iterations \u001b[38;5;241m/\u001b[39m num_batches \u001b[38;5;28;01mif\u001b[39;00m num_batches \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    319\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    320\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_iterations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m iter, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapprox_epochs\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    321\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal_iterations,\n\u001b[1;32m    322\u001b[0m     leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Changed from False to True\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_progress_bar\n\u001b[1;32m    324\u001b[0m )\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/torchdata/stateful_dataloader/stateful_dataloader.py:404\u001b[0m, in \u001b[0;36mStatefulDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/torchdata/stateful_dataloader/stateful_dataloader.py:1152\u001b[0m, in \u001b[0;36m_StatefulMultiProcessingDataLoaderIter._reset\u001b[0;34m(self, loader, first_iter, prime_prefetch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m resume_iteration_cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m resume_iteration_cnt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1152\u001b[0m     return_idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers_status):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA worker has failed during Resume! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers_status\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/torchdata/stateful_dataloader/stateful_dataloader.py:1369\u001b[0m, in \u001b[0;36m_StatefulMultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1369\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1370\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1371\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/torchdata/stateful_dataloader/stateful_dataloader.py:1228\u001b[0m, in \u001b[0;36m_StatefulMultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1227\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 5754, 5755, 5756, 5757, 5758, 5759, 5760) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Training G-Commutative S-N-VAE on dSprites =====\")\n",
    "model_g_comm_dsprites, loss_fn_g_comm_dsprites, optimizer_g_comm_dsprites = setup_g_commutative_components(\n",
    "    dsprites_dataset, \n",
    "    loss_kwargs_g_commutative,\n",
    "    latent_factor_topologies\n",
    ")\n",
    "\n",
    "# Setup trainer for G-Commutative model\n",
    "trainer_g_comm_dsprites = UnsupervisedTrainer(model=model_g_comm_dsprites,\n",
    "                                             loss=loss_fn_g_comm_dsprites,\n",
    "                                             optimizer=optimizer_g_comm_dsprites,\n",
    "                                             lr_scheduler=None,\n",
    "                                             determinism_kwargs=determinism_kwargs,\n",
    "                                             use_torch_compile=use_torch_compile,\n",
    "                                             return_logs=True,\n",
    "                                             return_chkpt=return_chkpt,\n",
    "                                             chkpt_save_path=chkpt_save_path,\n",
    "                                             chkpt_save_dir=chkpt_save_dir,\n",
    "                                             chkpt_every_n_steps=chkpt_every_n_steps,\n",
    "                                             chkpt_viz=chkpt_viz\n",
    "                                             )\n",
    "\n",
    "# Train the G-Commutative model\n",
    "print(f\"\\nStarting G-Commutative training for {num_train_steps} {train_step_unit}s...\")\n",
    "print(f\"Note: Group losses will be applied after {loss_kwargs_g_commutative['warm_up_steps']} warm-up steps\")\n",
    "trainer_g_comm_dsprites.train(max_steps=num_train_steps, step_unit=train_step_unit, dataloader=dsprites_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e579552",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Visualizing G-Commutative dSprites Results =====\")\n",
    "visualizer_g_comm_dsprites = utils.visualize.SNVAEVisualizer(vae_model=model_g_comm_dsprites, dataset=dsprites_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41688d96",
   "metadata": {},
   "source": [
    "# Results Visualization and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202a711",
   "metadata": {},
   "source": [
    "## Model Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9439949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting random reconstructions...\")\n",
    "visualizer_g_comm_dsprites.plot_random_reconstructions(10, mode='mean')\n",
    "plt.show()\n",
    "\n",
    "print(\"Plotting reconstructions from specific indices...\")\n",
    "indices_dsprites = [0, 10, 20, 30, 40, 50]  # Example indices\n",
    "visualizer_g_comm_dsprites.plot_reconstructions_sub_dataset(indices_dsprites, mode='mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34580b0d",
   "metadata": {},
   "source": [
    "## Latent Space Traversals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc24ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting latent traversals...\")\n",
    "visualizer_g_comm_dsprites.plot_all_latent_traversals(num_samples=15,\n",
    "                                                      r1_max_traversal_type='probability',\n",
    "                                                      r1_max_traversal=0.95,\n",
    "                                                      s1_max_traversal_type='fraction',\n",
    "                                                      s1_max_traversal=1.0,\n",
    "                                                      use_ref_img=True\n",
    "                                                      )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a reference image index for detailed analysis\n",
    "ref_img_idx_dsprites = 495  # Example index\n",
    "ref_img_dsprites = dsprites_dataset[ref_img_idx_dsprites][0]\n",
    "\n",
    "# Plot the reference image\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(ref_img_dsprites.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
    "plt.title(f\"Reference Image for Analysis (Index: {ref_img_idx_dsprites})\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Single latent traversal analysis\n",
    "latent_factor_idx = 0  # Index of the latent dimension to traverse\n",
    "print(f\"Plotting single latent traversal for dimension {latent_factor_idx}...\")\n",
    "visualizer_g_comm_dsprites.plot_single_latent_traversal(latent_factor_idx, \n",
    "                                                        ref_img=ref_img_dsprites, \n",
    "                                                        num_samples=11,\n",
    "                                                        max_traversal_type='fraction',\n",
    "                                                        max_traversal=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb032cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete latent traversal analysis using the reference image\n",
    "print(\"Plotting all latent traversals based on reference image...\")\n",
    "visualizer_g_comm_dsprites.plot_all_latent_traversals(ref_img=ref_img_dsprites, \n",
    "                                                      num_samples=15,\n",
    "                                                      r1_max_traversal_type='probability',\n",
    "                                                      r1_max_traversal=0.95,\n",
    "                                                      s1_max_traversal_type='fraction',\n",
    "                                                      s1_max_traversal=1\n",
    "                                                      )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
