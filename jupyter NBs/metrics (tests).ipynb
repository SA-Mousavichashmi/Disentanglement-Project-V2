{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f696f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root: /notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root by looking for .git or requirements.txt\n",
    "current = Path.cwd()\n",
    "while not any((current / marker).exists() for marker in ['.git', 'requirements.txt']):\n",
    "    if current.parent == current:\n",
    "        raise FileNotFoundError(\"Project root not found\")\n",
    "    current = current.parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "print(f\"Added project root: {current}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239f71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Add project root to path for imports\n",
    "# if not '..' in sys.path:\n",
    "#     sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76355d8b",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mixing_matrix(mixing_matrix, title=\"Ground Truth Mixing Matrix\"):\n",
    "    \"\"\"Visualize the relationship between factors and latents.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(mixing_matrix, annot=True, fmt=\".2f\", cmap=\"viridis\",\n",
    "                xticklabels=[f\"z{i}\" for i in range(mixing_matrix.shape[1])],\n",
    "                yticklabels=[f\"f{i}\" for i in range(mixing_matrix.shape[0])])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Latent Dimensions\")\n",
    "    plt.ylabel(\"Ground Truth Factors\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_metric_results(results, metric_name=\"DCId\"):\n",
    "    \"\"\"Visualize metric results across different disentanglement levels.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Extract relevant metrics\n",
    "    x = [r['level'] for r in results]\n",
    "    metrics = {k: [r[k] for r in results] for k in results[0].keys() if k != 'level'}\n",
    "    \n",
    "    # Plot each metric\n",
    "    for name, values in metrics.items():\n",
    "        plt.plot(x, values, 'o-', label=name)\n",
    "        \n",
    "    plt.xlabel('Disentanglement Level of Generated Data')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.title(f'{metric_name} Metrics vs True Disentanglement Level')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a62d44",
   "metadata": {},
   "source": [
    "# Artificial disentanglement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c40409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(factor_sizes, num_latents, disentanglement_level, noise_level):\n",
    "    \"\"\"\n",
    "    Generate synthetic data with controlled disentanglement properties.\n",
    "    All possible combinations of factor values will be generated.\n",
    "    \n",
    "    Parameters:\n",
    "    - factor_sizes: List where each element specifies the number of discrete values for that factor\n",
    "                   (length of list determines number of factors)\n",
    "    - num_latents: Number of latent dimensions\n",
    "    - disentanglement_level: How disentangled the representation should be (0-1)\n",
    "    - noise_level: Amount of noise to add\n",
    "    \n",
    "    Returns:\n",
    "    - gt_factors: Ground truth factors [num_samples, num_factors]\n",
    "    - latent_reps: Latent representations [num_samples, num_latents]\n",
    "    - mixing_matrix: Matrix showing how factors map to latents\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    # Determine number of factors from the length of factor_sizes\n",
    "    num_factors = len(factor_sizes)\n",
    "    \n",
    "    # Calculate total number of samples based on all combinations\n",
    "    num_samples = np.prod(factor_sizes)\n",
    "    \n",
    "    # Generate evenly spaced values for each factor\n",
    "    factor_values = []\n",
    "    for i in range(num_factors):\n",
    "        # Generate values from 0 to 1 with factor_sizes[i] discrete values\n",
    "        factor_values.append(np.linspace(0, 1, factor_sizes[i]))\n",
    "    \n",
    "    # Generate all combinations of factor values\n",
    "    all_combinations = list(itertools.product(*factor_values))\n",
    "    \n",
    "    # Create ground truth factors from all combinations\n",
    "    gt_factors = np.array(all_combinations)\n",
    "    \n",
    "    # Create a mixing matrix that defines how factors map to latents\n",
    "    # For perfect disentanglement, this would be an identity matrix (with zeros for any extra dimensions)\n",
    "    mixing_matrix = np.zeros((num_factors, num_latents))\n",
    "    \n",
    "    # Set up the mixing based on disentanglement level\n",
    "    for i in range(num_factors):\n",
    "        # Primary dimension gets most of the weight based on disentanglement level\n",
    "        primary_dim = i % num_latents  # In case we have more factors than latents\n",
    "        mixing_matrix[i, primary_dim] = disentanglement_level\n",
    "        \n",
    "        # Distribute remaining weight across other dimensions\n",
    "        remaining = 1.0 - disentanglement_level\n",
    "        other_dims = [j for j in range(num_latents) if j != primary_dim]\n",
    "        if other_dims:  # Check if there are other dimensions\n",
    "            for j in other_dims:\n",
    "                mixing_matrix[i, j] = remaining / len(other_dims)\n",
    "    \n",
    "    # Generate latent representations based on the mixing matrix\n",
    "    latent_reps = np.dot(gt_factors, mixing_matrix)\n",
    "    \n",
    "    # Add some noise to make it more realistic\n",
    "    latent_reps += np.random.normal(0, noise_level, latent_reps.shape)\n",
    "    \n",
    "    return gt_factors, latent_reps, mixing_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e17e1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 4000\n",
      "gt factors shape: (4000, 5) latent reps shape: (4000, 10) mixing matrix shape: (5, 10)\n"
     ]
    }
   ],
   "source": [
    "factor_sizes = [10, 5, 5, 4, 4]  # Number of discrete values for each factor\n",
    "num_latents = 10  # Number of latent dimensions\n",
    "disentanglement_level = 0.7  # Disentanglement level (0-1)\n",
    "noise_level = 0.01  # Noise level to add to the latent representations\n",
    "total_samples = np.prod(factor_sizes)  # Total number of samples based on all combinations\n",
    "\n",
    "print(\"Total samples:\", total_samples)\n",
    "\n",
    "# Generate synthetic disentangled data\n",
    "gt_factors, latent_reps, mixing_matrix = generate_synthetic_data(\n",
    "    factor_sizes, num_latents, disentanglement_level, noise_level\n",
    ")\n",
    "\n",
    "print(\"gt factors shape:\", gt_factors.shape, \"latent reps shape:\", latent_reps.shape, \"mixing matrix shape:\", mixing_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17561ac",
   "metadata": {},
   "source": [
    "# DCI_d\n",
    "\n",
    "Testing the Disentanglement, Completeness, and Informativeness (DCI) metric with synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff48798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.dci_d import DCId\n",
    "\n",
    "\n",
    "train_ratio_dci_d = 0.8\n",
    "\n",
    "dci_d_num_train = int(train_ratio_dci_d * total_samples) \n",
    "dci_d_num_test = total_samples - dci_d_num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c47af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disentanglement: 0.9920950525911718\n",
      "completeness: 0.9595907445931786\n",
      "informativeness_train_scores: 1.0\n",
      "informativeness_test_scores: 0.9955\n",
      "informativeness_train_errors: 0.0\n",
      "informativeness_test_errors: 0.004499999999999993\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy arrays to torch tensors\n",
    "\n",
    "# Initialize the DCId metric\n",
    "dci_metric = DCId(num_train=dci_d_num_train, num_test=dci_d_num_test, backend='sklearn', num_workers=4)\n",
    "\n",
    "# Compute the metric\n",
    "dci_results = dci_metric(latent_reps, gt_factors)\n",
    "\n",
    "for key, value in dci_results.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d727d",
   "metadata": {},
   "source": [
    "# MIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7af63fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIG Score: 0.8981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from metrics.mig import MIG\n",
    "\n",
    "# Set the parameters for MIG calculation\n",
    "mig_num_bins = 20\n",
    "mig_num_workers = 8\n",
    "\n",
    "# Initialize the MIG metric\n",
    "mig_metric = MIG(num_bins=mig_num_bins, num_workers=mig_num_workers, mi_method='pyitlib', entropy_method='pyitlib')\n",
    "\n",
    "# We can reuse the same tensors we used for DCI_d\n",
    "# Compute the metric\n",
    "mig_result = mig_metric(latent_reps, gt_factors)\n",
    "\n",
    "print(f\"MIG Score: {mig_result:.4f}\") # TODO check the correctness of this metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7c14b2",
   "metadata": {},
   "source": [
    "# Modularity_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfcae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularityd Score: 0.6071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from metrics.modularity_d import Modularityd\n",
    "\n",
    "# Set the parameters for Modularityd calculation\n",
    "modularity_d_num_bins = 20\n",
    "modularity_d_num_workers = 4\n",
    "\n",
    "# Initialize the Modularityd metric\n",
    "modularity_d_metric = Modularityd(num_bins=modularity_d_num_bins, num_workers=modularity_d_num_workers, mi_method='numpy', device='cpu')\n",
    "\n",
    "# Compute the metric\n",
    "modularity_d_result = modularity_d_metric(latent_reps, gt_factors)\n",
    "print(f\"Modularityd Score: {modularity_d_result:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
