{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8215de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Find project root by looking for .git or requirements.txt\n",
    "# current = Path.cwd()\n",
    "# while not any((current / marker).exists() for marker in ['.git', 'requirements.txt']):\n",
    "#     if current.parent == current:\n",
    "#         raise FileNotFoundError(\"Project root not found\")\n",
    "#     current = current.parent\n",
    "\n",
    "# sys.path.append(str(current))\n",
    "# print(f\"Added project root: {current}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc66bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.io import load_chkpt, create_trainer_from_chkpt, get_dataloader_from_chkpt\n",
    "from metrics.utils import MetricAggregator\n",
    "from utils.visualize import Visualizer\n",
    "from datasets import get_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30b65338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from checkpoints/tests/b-vae-16-epoch-20-gaussian.pt on original.\n",
      "Determinism settings applied from checkpoint: {'seed': 0, 'use_cuda_det': True, 'enforce_det': False, 'cublas_workspace_config': None}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'return_log_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m chkpt \u001b[38;5;241m=\u001b[39m load_chkpt(chkpt_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create trainer from checkpoint\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_trainer_from_chkpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchkpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_exact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# model = load_model_chkpt(chkpt)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchkpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/notebooks/utils/io.py:691\u001b[0m, in \u001b[0;36mcreate_trainer_from_chkpt\u001b[0;34m(ckpt, create_exact, new_model, new_loss, new_optimizer, new_dataloader, new_lr_scheduler, additional_trainer_kwargs, device)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_trainer_from_chkpt\u001b[39m(ckpt,\n\u001b[1;32m    672\u001b[0m                               create_exact\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    673\u001b[0m                               new_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m                               device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    680\u001b[0m                               ):\n\u001b[1;32m    681\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;124;03m    Creates a trainer instance from a checkpoint, with optional replacement of components.\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \n\u001b[1;32m    684\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m    ckpt: dict\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m        A dictionary containing the checkpoint data.\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03m    additional_trainer_kwargs: dict, optional\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m        Additional keyword arguments to pass to the BaseTrainer constructor.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    new_model: torch.nn.Module, optional\u001b[39;00m\n\u001b[0;32m--> 691\u001b[0m \u001b[38;5;124;03m        If provided, use this model instead of loading from checkpoint.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;124;03m    new_loss: losses.baseloss.BaseLoss, optional\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;124;03m        If provided, use this loss function instead of loading from checkpoint.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    new_optimizer: torch.optim.Optimizer, optional\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m        If provided, use this optimizer instead of loading from checkpoint.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;124;03m    new_lr_scheduler: torch.optim.lr_scheduler._LRScheduler, optional\u001b[39;00m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;124;03m        If provided, use this learning rate scheduler instead of loading from checkpoint.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;124;03m    device: torch.device, optional\u001b[39;00m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;124;03m        If provided, use this device instead of the one stored in the checkpoint.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;124;03m        Defaults to CUDA if available, else CPU.\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \n\u001b[1;32m    702\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;124;03m    BaseTrainer:\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m        An instance of the BaseTrainer class initialized with components from the checkpoint\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;124;03m        or with the provided new components.\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;03m        If any of new_model, new_loss, new_optimizer, or new_lr_scheduler are provided,\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m        train_id will be set to a new UUID.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m create_exact:\n\u001b[1;32m    712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m create_trainer_from_chkpt_exact(ckpt, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/notebooks/utils/io.py:615\u001b[0m, in \u001b[0;36mcreate_trainer_from_chkpt_exact\u001b[0;34m(chkpt, device)\u001b[0m\n\u001b[1;32m    612\u001b[0m # Recreate dataloader with exact settings\n\u001b[1;32m    613\u001b[0m dataloader = get_dataloader_from_chkpt(chkpt)\n\u001b[0;32m--> 615\u001b[0m # Extract training logs\n\u001b[1;32m    616\u001b[0m train_iter_num = chkpt['train_iter_num']\n\u001b[1;32m    617\u001b[0m train_losses_log = chkpt['logs']['train']['loss_results']\n",
      "\u001b[0;31mKeyError\u001b[0m: 'return_log_loss'"
     ]
    }
   ],
   "source": [
    "# Path to your checkpoint file\n",
    "chkpt_path = 'checkpoints/tests/b-vae-16-epoch-20-gaussian.pt'\n",
    "\n",
    "# Load the checkpoint\n",
    "chkpt = load_chkpt(chkpt_path)\n",
    "\n",
    "# Create trainer from checkpoint\n",
    "trainer = create_trainer_from_chkpt(chkpt, create_exact=True)\n",
    "\n",
    "# model = load_model_chkpt(chkpt)\n",
    "\n",
    "print(f\"Model loaded from {chkpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b65677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from checkpoint\n",
    "dataset_info = chkpt['dataset']\n",
    "dataset_name = dataset_info['name']\n",
    "dataset_kwargs = dataset_info['kwargs']\n",
    "dataset_class = get_dataset(dataset_name)\n",
    "dataset = dataset_class(**dataset_kwargs)\n",
    "\n",
    "# Create dataloader from checkpoint\n",
    "dataloader = get_dataloader_from_chkpt(chkpt)\n",
    "\n",
    "print(f\"Dataset {dataset_name} loaded with {len(dataset)} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_compute = [\n",
    "    {'name': 'dci_d', 'args':{'num_train':5000, 'num_test':1000}}, # Example args\n",
    "    {'name': 'mig', 'args':{'num_bins':100, 'mi_method':'numpy', 'entropy_method':'numpy'}} # Example args\n",
    "]\n",
    "\n",
    "metric_aggregator = MetricAggregator(metrics=metrics_to_compute)\n",
    "\n",
    "print(\"\\n===== Computing Metrics =====\")\n",
    "metrics_results = metric_aggregator.compute(model=model, \n",
    "                                            data_loader=dataloader, \n",
    "                                            device=trainer.device)\n",
    "print(\"Metrics Results:\", metrics_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aacbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = Visualizer(vae_model=model, dataset=dataset)\n",
    "\n",
    "print(\"\\n===== Visualizing Reconstructions =====\")\n",
    "visualizer.plot_random_reconstructions(10, mode='mean')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n===== Visualizing Latent Traversals =====\")\n",
    "visualizer.plot_all_latent_traversals(num_samples=20)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
