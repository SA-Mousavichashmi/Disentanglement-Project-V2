{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2cdb25",
   "metadata": {},
   "source": [
    "# SN-GAN Training on Shapes3D Dataset\n",
    "\n",
    "This notebook demonstrates training a Spectral Normalization GAN (SN-GAN) on the Shapes3D dataset using the custom GAN framework.\n",
    "\n",
    "## Overview\n",
    "- **Model**: SN-GAN with spectral normalization for improved training stability\n",
    "- **Dataset**: Shapes3D - 3D shapes with 6 controllable factors of variation\n",
    "- **Goal**: Generate realistic 3D shape images\n",
    "\n",
    "The SN-GAN uses spectral normalization in the discriminator to control the Lipschitz constant, leading to more stable training compared to vanilla GANs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Add the project root to the path to import our modules\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Import our custom modules\n",
    "from datasets.shapes3d import Shapes3D\n",
    "from gan.trainer import GANTrainer\n",
    "from gan.architecture import Generator, Discriminator\n",
    "from gan.loss import get_loss\n",
    "\n",
    "# Set up device and random seeds for reproducibility\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# For consistent results\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4545fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Configuration\n",
    "print(\"Setting up Shapes3D dataset...\")\n",
    "\n",
    "# For this experiment, we'll allow all factors to vary\n",
    "# This gives us the full diversity of the dataset\n",
    "selected_factors = ['floorCol', 'wallCol', 'objCol', 'objSize', 'objType', 'objAzimuth']\n",
    "not_selected_factors_index_value = {}  # Empty since we're selecting all factors\n",
    "\n",
    "# Create dataset instance\n",
    "dataset = Shapes3D(\n",
    "    selected_factors=selected_factors,\n",
    "    not_selected_factors_index_value=not_selected_factors_index_value,\n",
    "    root='../../data/shapes3d/',\n",
    "    subset=0.1  # Use 10% of data for faster training (48k images)\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded with {len(dataset)} images\")\n",
    "print(f\"Image size: {dataset.img_size}\")\n",
    "print(f\"Selected factors: {dataset.selected_factors}\")\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=4 if device.type == 'cuda' else 0,\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created with batch size: {batch_size}\")\n",
    "print(f\"Number of batches: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample data\n",
    "def show_data_samples(dataset, n_samples=16):\n",
    "    \"\"\"Display a grid of sample images from the dataset.\"\"\"\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        img, factors = dataset[i]\n",
    "        \n",
    "        # Convert from tensor to numpy and transpose for matplotlib\n",
    "        img_np = img.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        axes[i].imshow(img_np)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'Sample {i+1}', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Shapes3D Dataset Samples', fontsize=16, y=0.98)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Sample images from the Shapes3D dataset:\")\n",
    "show_data_samples(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf08c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SN-GAN Configuration\n",
    "print(\"Setting up SN-GAN trainer...\")\n",
    "\n",
    "# Model hyperparameters\n",
    "latent_dim = 100\n",
    "img_size = (3, 64, 64)  # C, H, W\n",
    "learning_rate_g = 2e-4\n",
    "learning_rate_d = 2e-4\n",
    "beta1 = 0.0  # SN-GAN typically uses beta1=0\n",
    "beta2 = 0.9\n",
    "\n",
    "# Create SN-GAN trainer\n",
    "# The 'sngan' loss type will automatically use spectral normalization in the discriminator\n",
    "trainer = GANTrainer(\n",
    "    generator=None,  # Will create default generator\n",
    "    discriminator=None,  # Will create default discriminator with spectral norm\n",
    "    loss_type='sngan',  # This uses hinge loss and spectral normalization\n",
    "    loss_kwargs={},\n",
    "    g_lr=learning_rate_g,\n",
    "    d_lr=learning_rate_d,\n",
    "    beta1=beta1,\n",
    "    beta2=beta2,\n",
    "    device=device,\n",
    "    latent_dim=latent_dim,\n",
    "    img_size=img_size,\n",
    "    n_critic=1  # Update generator every discriminator update\n",
    ")\n",
    "\n",
    "print(f\"SN-GAN trainer created\")\n",
    "print(f\"Generator parameters: {sum(p.numel() for p in trainer.generator.parameters()):,}\")\n",
    "print(f\"Discriminator parameters: {sum(p.numel() for p in trainer.discriminator.parameters()):,}\")\n",
    "print(f\"Loss type: {trainer.loss_type}\")\n",
    "print(f\"Device: {trainer.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e806cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "epochs = 50  # Adjust based on your computational resources\n",
    "print(f\"Starting SN-GAN training for {epochs} epochs...\")\n",
    "\n",
    "# Train the model\n",
    "trainer.train(dataloader, epochs)\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ed742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Training Progress\n",
    "print(\"Plotting training losses...\")\n",
    "trainer.plot_losses()\n",
    "\n",
    "# Show training history summary\n",
    "if trainer.history['d_loss'] and trainer.history['g_loss']:\n",
    "    print(f\"\\nTraining Summary:\")\n",
    "    print(f\"Final Discriminator Loss: {trainer.history['d_loss'][-1]:.4f}\")\n",
    "    print(f\"Final Generator Loss: {trainer.history['g_loss'][-1]:.4f}\")\n",
    "    print(f\"Average Discriminator Loss: {np.mean(trainer.history['d_loss']):.4f}\")\n",
    "    print(f\"Average Generator Loss: {np.mean(trainer.history['g_loss']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5990b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and Display Sample Images\n",
    "print(\"Generating sample images from trained SN-GAN...\")\n",
    "\n",
    "# Generate samples using the trained generator\n",
    "trainer.plot_samples(n_samples=16, n_cols=4, figsize=(10, 10))\n",
    "\n",
    "# Generate more samples for variety\n",
    "print(\"\\nGenerating additional samples...\")\n",
    "trainer.plot_samples(n_samples=25, n_cols=5, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Space Exploration\n",
    "print(\"Exploring latent space interpolations...\")\n",
    "\n",
    "def interpolate_latent_space(trainer, n_interpolations=8, figsize=(15, 6)):\n",
    "    \"\"\"Create interpolations between two random points in latent space.\"\"\"\n",
    "    trainer.generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generate two random latent vectors\n",
    "        z1 = trainer.generate_noise(1)\n",
    "        z2 = trainer.generate_noise(1)\n",
    "        \n",
    "        # Create interpolation weights\n",
    "        alphas = torch.linspace(0, 1, n_interpolations, device=trainer.device)\n",
    "        \n",
    "        interpolated_images = []\n",
    "        for alpha in alphas:\n",
    "            # Linear interpolation between z1 and z2\n",
    "            z_interp = alpha * z2 + (1 - alpha) * z1\n",
    "            fake_img = trainer.generator(z_interp)\n",
    "            \n",
    "            # Denormalize and convert to displayable format\n",
    "            fake_img = (fake_img + 1) / 2\n",
    "            fake_img = torch.clamp(fake_img, 0, 1)\n",
    "            interpolated_images.append(fake_img.cpu())\n",
    "        \n",
    "        # Plot interpolations\n",
    "        fig, axes = plt.subplots(1, n_interpolations, figsize=figsize)\n",
    "        for i, img in enumerate(interpolated_images):\n",
    "            img_np = img[0].permute(1, 2, 0).numpy()\n",
    "            axes[i].imshow(img_np)\n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(f'Î±={alphas[i]:.2f}', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('Latent Space Interpolation', fontsize=14, y=0.98)\n",
    "        plt.show()\n",
    "    \n",
    "    trainer.generator.train()\n",
    "\n",
    "# Perform several interpolations\n",
    "for i in range(3):\n",
    "    print(f\"Interpolation {i+1}:\")\n",
    "    interpolate_latent_space(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbb690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Trained Models and Final Evaluation\n",
    "import datetime\n",
    "\n",
    "# Create timestamp for unique filename\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = f\"../../checkpoints/sngan_shapes3d_{timestamp}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Saving models to: {save_dir}\")\n",
    "\n",
    "# Save generator and discriminator\n",
    "torch.save({\n",
    "    'generator_state_dict': trainer.generator.state_dict(),\n",
    "    'discriminator_state_dict': trainer.discriminator.state_dict(),\n",
    "    'g_optimizer_state_dict': trainer.g_optimizer.state_dict(),\n",
    "    'd_optimizer_state_dict': trainer.d_optimizer.state_dict(),\n",
    "    'history': trainer.history,\n",
    "    'config': {\n",
    "        'latent_dim': latent_dim,\n",
    "        'img_size': img_size,\n",
    "        'loss_type': trainer.loss_type,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rates': {'g_lr': learning_rate_g, 'd_lr': learning_rate_d},\n",
    "        'betas': {'beta1': beta1, 'beta2': beta2}\n",
    "    }\n",
    "}, os.path.join(save_dir, 'sngan_checkpoint.pth'))\n",
    "\n",
    "# Save loss plots\n",
    "trainer.plot_losses(save_path=os.path.join(save_dir, 'training_losses.png'))\n",
    "\n",
    "# Save sample images\n",
    "trainer.plot_samples(n_samples=25, n_cols=5, figsize=(12, 12), \n",
    "                    save_path=os.path.join(save_dir, 'generated_samples.png'))\n",
    "\n",
    "print(\"Model and results saved successfully!\")\n",
    "print(f\"\\nSN-GAN Training Summary:\")\n",
    "print(f\"- Dataset: Shapes3D (subset: {dataset.subset*100:.1f}%)\")\n",
    "print(f\"- Total images trained on: {len(dataset):,}\")\n",
    "print(f\"- Epochs: {epochs}\")\n",
    "print(f\"- Batch size: {batch_size}\")\n",
    "print(f\"- Latent dimension: {latent_dim}\")\n",
    "print(f\"- Loss type: {trainer.loss_type}\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Save directory: {save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAVLAB-Server (Dis Project)",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
