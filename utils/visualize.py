import matplotlib.pyplot as plt
import torch
from vae_models import utils as model_utils # Import the vae_models utils

class Visualizer():
    def __init__(self, vae_model, dataset):
        """Initializes the visualizer class.

        Parameters
        ----------
        vae_model : torch.nn.Module
            The trained VAE model used for generating images and reconstructions.
        dataset : torch.utils.data.Dataset
            The dataset from which images will be sampled for visualization tasks.
        """
        
        self.vae_model = vae_model # The vae model for generating images
        self.dataset = dataset # the dataset to be used for visualization

################## Latent Traversal Methods ##################

    def plot_single_latent_traversal(self, 
                                     latent_idx,
                                     num_samples=10,
                                     use_ref_img=True, 
                                     ref_img=None,
                                     use_ref_img_lat_std=False, 
                                     max_traversal_type: str = 'probability', 
                                     max_traversal: float = 0.95,
                                     figsize=(10, 3) 
                                     ):
        
        """Plots the images generated by traversing a single latent dimension.

        Generates images by varying the specified latent dimension while keeping others
        fixed, and then displays these images in a row.

        Parameters
        ----------
        latent_idx : int
            The index of the latent dimension to traverse.
        num_samples : int, optional
            The number of steps or images to generate and plot along the traversal.
            Defaults to 10.
        use_ref_img : bool, optional
            If True, uses a reference image for traversal. If False, traversal is
            based on the prior (mean=0, std=1). Defaults to True.
        ref_img : torch.Tensor, optional
            A reference image tensor (C, H, W) to base the traversal on. Used if
            `use_ref_img` is True. If None and `use_ref_img` is True, a random
            image from the dataset is selected. Defaults to None.
        use_ref_img_lat_std : bool, optional
            If True and `use_ref_img` is True, the traversal range is scaled by the
            standard deviation of the reference image's latent encoding. Otherwise,
            a unit standard deviation is assumed. Defaults to False.
        max_traversal_type : str, optional
            Specifies how the traversal range is determined. Must be either 'probability'
            or 'absolute'. Defaults to 'probability'.
        max_traversal : float, optional
            The maximum traversal value, interpreted based on `max_traversal_type`.
            Defaults to 0.475.
        figsize : tuple, optional
            The size of the matplotlib figure. Defaults to (10, 3).
        """

        if use_ref_img and ref_img is None:
            # Randomly select an index from the dataset when ref_img is None
            random_idx = torch.randint(0, len(self.dataset), (1,)).item() # Randomly select an index from the dataset
            ref_img = self.dataset[random_idx][0] # Get the image tensor from the dataset

        else:
            ref_img = None # Use the prior (mean=0, std=1) for traversal
        
        # Generate the traversal images using the function from vae_models.utils
        traversal_images = model_utils.traverse_single_latent(
            vae_model=self.vae_model, 
            latent_idx=latent_idx,
            num_samples=num_samples, 
            max_traversal_type=max_traversal_type, 
            max_traversal=max_traversal,  
            ref_img=ref_img,
            use_ref_img_lat_std=use_ref_img_lat_std
        )
        
        # Create the plot
        fig, axes = plt.subplots(1, num_samples, figsize=figsize)

        # Handle case where num_samples is 1, axes is not an array
        if num_samples == 1:
            axes = [axes]

        for i, ax in enumerate(axes):
            img = traversal_images[i].permute(1, 2, 0).numpy() # Convert CHW to HWC for plotting
            ax.imshow(img)
            ax.axis('off')

        fig.suptitle(f'Traversal of Latent Dimension {latent_idx}', fontsize=12, y=0.95)  # Adjust title position
        plt.tight_layout(rect=[0, 0, 1, 0.95])  # Reduce the top margin
        plt.show()

    def plot_all_latent_traversals(self,
                                     num_samples=10,
                                     use_ref_img=True, 
                                     ref_img=None,
                                     use_ref_img_lat_std=False,  
                                     max_traversal_type: str = 'probability', 
                                     max_traversal: float = 0.95,
                                     figsize=(10, 3)
                                     ):
        """Plots images generated by traversing each latent dimension individually.

        Generates images by varying each latent dimension while keeping others fixed,
        and then displays these images in a grid, with each row corresponding to a
        latent dimension.

        Parameters
        ----------
        num_samples : int, optional
            The number of steps or images to generate and plot along each traversal.
            Defaults to 10.
        use_ref_img : bool, optional
            If True, uses a reference image for traversal. If False, traversal is
            based on the prior (mean=0, std=1). Defaults to True.
        ref_img : torch.Tensor, optional
            A reference image tensor (C, H, W) to base the traversal on. Used if
            `use_ref_img` is True. If None and `use_ref_img` is True, a random
            image from the dataset is selected. Defaults to None.
        use_ref_img_lat_std : bool, optional
            If True and `use_ref_img` is True, the traversal range is scaled by the
            standard deviation of the reference image's latent encoding for each
            dimension. Otherwise, a unit standard deviation is assumed. Defaults to False.
        max_traversal_type : str, optional
            Specifies how the traversal range is determined. Must be either 'probability'
            or 'absolute'. Defaults to 'probability'.
        max_traversal : float, optional
            The maximum traversal value, interpreted based on `max_traversal_type`.
            Defaults to 0.475.
        figsize : tuple, optional
            The base size of the matplotlib figure for a single row. The total height
            will be adjusted based on the number of latent dimensions. Defaults to (10, 3).

        """

        if use_ref_img and ref_img is None:
            # Randomly select an index from the dataset when ref_img is None
            random_idx = torch.randint(0, len(self.dataset), (1,)).item() # Randomly select an index from the dataset
            ref_img = self.dataset[random_idx][0] # Get the image tensor from the dataset

        else:
            ref_img = None # Use the prior (mean=0, std=1) for traversal
            
        # Generate the traversal images for all latent dimensions using the function from vae_models.utils
        all_traversals = model_utils.traverse_all_latents(
            vae_model=self.vae_model,
            num_samples=num_samples, 
            max_traversal_type=max_traversal_type, 
            max_traversal=max_traversal, 
            ref_img=ref_img,
            use_ref_img_lat_std=use_ref_img_lat_std
        )

        num_latent_dims = self.vae_model.latent_dim

        # Adjust figure height based on the number of latent dimensions
        total_height = figsize[1] * num_latent_dims / 3 # Heuristic adjustment
        fig, axes = plt.subplots(num_latent_dims, num_samples, figsize=(figsize[0], total_height))

        # Handle cases where subplot returns a 1D array or a single Axes object
        if num_latent_dims == 1 and num_samples == 1:
            axes = [[axes]]
        elif num_latent_dims == 1:
            axes = [axes]
        elif num_samples == 1:
            axes = axes.reshape(-1, 1)

        for latent_idx in range(num_latent_dims):
            traversal_images = all_traversals[latent_idx]
            for sample_idx in range(num_samples):
                ax = axes[latent_idx][sample_idx]
                img = traversal_images[sample_idx].permute(1, 2, 0).numpy() # Convert CHW to HWC
                ax.imshow(img)
                ax.axis('off')
                # Add a title to the first image of each row indicating the latent dimension
                if sample_idx == 0:
                    ax.text(-0.1, 0.5, f'Latent {latent_idx}', horizontalalignment='right',
                            verticalalignment='center', transform=ax.transAxes, fontsize=8)

        # Adjust layout to prevent overlap and add a main title
        plt.tight_layout(pad=0.1, h_pad=0.5, w_pad=0.1)
        fig.suptitle('Latent Traversals for All Dimensions', fontsize=12, y=1.02) # Adjust y position of suptitle
        plt.show()


################## Reconstruction Methods ##################

    def plot_reconstructions(self, imgs, reconstructions, figsize=(10, 3)):
        """Plots original images and their reconstructions side-by-side.

        Creates a matplotlib figure displaying the original images in the top row
        and their corresponding reconstructions in the bottom row.

        Parameters
        ----------
        imgs : list of torch.Tensor
            A list of original image tensors (on CPU).
        reconstructions : list of torch.Tensor
            A list of reconstructed image tensors (on CPU).
        figsize : tuple, optional
            The size of the matplotlib figure. Defaults to (10, 3).
        """
        num_images = len(imgs)
        fig, axes = plt.subplots(2, num_images, figsize=figsize)

        # Handle case where num_images is 1, axes is not a 2D array
        if num_images == 1:
            axes = axes.reshape(2, 1)

        for i in range(num_images):
            # Plot original image
            ax = axes[0, i]
            img = imgs[i].permute(1, 2, 0).numpy() # Convert CHW to HWC for plotting
            ax.imshow(img)
            ax.axis('off')
            if i == 0:
                ax.set_title('Original', fontsize=10)

            # Plot reconstructed image
            ax = axes[1, i]
            recon = reconstructions[i].permute(1, 2, 0).numpy() # Convert CHW to HWC
            ax.imshow(recon)
            ax.axis('off')
            if i == 0:
                ax.set_title('Reconstruction', fontsize=10)

        plt.tight_layout(pad=0.1)
        plt.show()
    
    def plot_random_reconstructions(self, num_samples=10, mode='mean', figsize=(10, 3)):
        """Randomly selects and plots a specified number of images and their reconstructions.

        This method combines the functionality of `random_reconstruct_sub_dataset` and
        `plot_reconstructions` to display a set of randomly chosen images alongside
        their VAE reconstructions.

        Parameters
        ----------
        num_samples : int, optional
            The number of random images to select and reconstruct. Defaults to 10.
        mode : str, optional
            Mode for reconstruction. Options are 'mean' or 'sample'. Defaults to 'mean'.
        figsize : tuple, optional
            The size of the matplotlib figure. Defaults to (10, 3).
        """
        imgs, reconstructions = model_utils.random_reconstruct_sub_dataset(self.vae_model, self.dataset, num_samples, mode=mode)
        self.plot_reconstructions(imgs, reconstructions, figsize)
    
    def plot_reconstructions_sub_dataset(self, img_indices, mode='mean', figsize=(10, 3)):
        """Reconstructs and plots images from the dataset specified by their indices.

        This method combines the functionality of `reconstruct_sub_dataset` and
        `plot_reconstructions` to display a set of images alongside their VAE
        reconstructions.

        Parameters
        ----------
        img_indices : list of int or torch.Tensor
            A list or tensor containing the indices of the images to reconstruct
            from the dataset.
        mode : str, optional
            Mode for reconstruction. Options are 'mean' or 'sample'. Defaults to 'mean'.
        figsize : tuple, optional
            The size of the matplotlib figure. Defaults to (10, 3).
        """
        imgs, reconstructions = model_utils.reconstruct_sub_dataset(self.vae_model, self.dataset, img_indices, mode=mode)
        self.plot_reconstructions(imgs, reconstructions, figsize)





