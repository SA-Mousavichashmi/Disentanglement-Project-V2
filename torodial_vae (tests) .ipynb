{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f68db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils.visualize\n",
    "from trainers import UnsupervisedTrainer\n",
    "import losses\n",
    "import vae_models\n",
    "from datasets import get_dataset\n",
    "from utils.io import find_optimal_num_workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d8255",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab80ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- General Hyperparameters ---\n",
    "model_name = 'toroidal_vae_burgess'  # Name of the model architecture file (e.g., 'vae_burgess')\n",
    "latent_factor_num = 10\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "rec_dist = 'bernoulli'  # Reconstruction distribution (e.g., 'bernoulli', 'gaussian')\n",
    "\n",
    "# train_step_unit = 'iteration'  # Unit for training steps ('epoch' or 'iteration')\n",
    "# num_train_steps = int(3e5)  # Number of training steps \n",
    "\n",
    "train_step_unit = 'epoch'  # Unit for training steps ('epoch' or 'iteration')\n",
    "num_train_steps = 5  # Number of training steps (epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0cce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss Specific Hyperparameters ---\n",
    "# Beta VAE\n",
    "loss_name = 'beta_toroidal_vae' \n",
    "loss_kwargs = {\n",
    "    'beta': 16,\n",
    "    'rec_dist': rec_dist\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572dfd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AnnealedVAE\n",
    "# loss_name = 'annealedvae'  \n",
    "# loss_kwargs = {\n",
    "#     'C_init': 0.0,\n",
    "#     'C_fin_3dshapes': 25.0,\n",
    "#     'C_fin_dsprites': 15.0,\n",
    "#     'gamma_annealed': 100.0,\n",
    "#     'anneal_steps': 10000,\n",
    "#     'rec_dist': rec_dist,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81d720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BetaTCVAE\n",
    "# loss_name = 'betatcvae'\n",
    "# loss_kwargs = {\n",
    "#     'alpha_tc': 1.0,\n",
    "#     'beta_tc_3dshapes': 6.0,\n",
    "#     'beta_tc_dsprites': 4.0,\n",
    "#     'gamma_tc': 1.0,\n",
    "#     'is_mss': True,\n",
    "#     'rec_dist': rec_dist\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "272979c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Factor VAE\n",
    "\n",
    "# loss_name = 'factorvae'\n",
    "# loss_kwargs = {\n",
    "#     'device': device,\n",
    "#     'gamma': 6.4,\n",
    "#     'discr_lr': 5e-5,\n",
    "#     'discr_betas': (0.5, 0.9),\n",
    "#     'rec_dist': rec_dist,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e053bc",
   "metadata": {},
   "source": [
    "## 3. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2942d0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3D Shapes dataset with 480000 samples.\n",
      "Loaded dSprites dataset with 737280 samples.\n"
     ]
    }
   ],
   "source": [
    "# Load 3D Shapes\n",
    "Shapes3D = get_dataset(\"shapes3d\")\n",
    "shapes3d_dataset = Shapes3D(selected_factors='all', not_selected_factors_index_value=None)\n",
    "# num_workers_3dshapes = find_optimal_num_workers(shapes3d_dataset, batch_size=batch_size, num_batches_to_test='all')\n",
    "num_workers_3dshapes = 4\n",
    "\n",
    "shapes3d_dataloader = torch.utils.data.DataLoader(shapes3d_dataset, batch_size=batch_size, num_workers=num_workers_3dshapes, shuffle=True, pin_memory=True)\n",
    "print(f\"Loaded 3D Shapes dataset with {len(shapes3d_dataset)} samples.\")\n",
    "\n",
    "# Load dSprites\n",
    "Dsprites = get_dataset('dsprites')\n",
    "\n",
    "dsprites_dataset = Dsprites(selected_factors='all', not_selected_factors_index_value=None)\n",
    "# num_workers_dsprites = find_optimal_num_workers(dsprites_dataset, batch_size=batch_size, num_batches_to_test='all')\n",
    "num_workers_dsprites = 7\n",
    "\n",
    "dsprites_dataloader = torch.utils.data.DataLoader(dsprites_dataset, batch_size=batch_size, num_workers=num_workers_dsprites, shuffle=True, pin_memory=True)\n",
    "print(f\"Loaded dSprites dataset with {len(dsprites_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ad3aa",
   "metadata": {},
   "source": [
    "## 4. Setup Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57116ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_components(dataset, loss_kwargs):\n",
    "    \"\"\"Instantiates model, loss function, and optimizer based on config.\"\"\"\n",
    "    img_size = dataset[0][0].shape\n",
    "    n_data = len(dataset)\n",
    "    \n",
    "\n",
    "    # Instantiate Model\n",
    "    model = vae_models.select(name=model_name, img_size=img_size, latent_factor_num=latent_factor_num)\n",
    "\n",
    "    if loss_name == 'betatcvae':\n",
    "        loss_kwargs['n_data'] = n_data\n",
    "    \n",
    "    loss_fn = losses.select(loss_name, **loss_kwargs)\n",
    "\n",
    "    # Instantiate Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"--- Setup for {dataset.__class__.__name__} --- \")\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Loss: {loss_fn.__class__.__name__} (rec_dist={rec_dist}), kwargs={loss_kwargs}\")\n",
    "    print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "    print(f\"---------------------------\")\n",
    "\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354ebcb",
   "metadata": {},
   "source": [
    "## 5. Train and Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae44524",
   "metadata": {},
   "source": [
    "## 5.1 - 3D Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "017cfdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes3d_loss_kwargs =  {\n",
    "     'beta': 16,\n",
    "     'rec_dist': rec_dist\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03c610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training on 3D Shapes =====\n",
      "--- Setup for Shapes3D --- \n",
      "Model: Model\n",
      "Loss: BetaToroidalVAELoss (rec_dist=bernoulli), kwargs={'beta': 16, 'rec_dist': 'bernoulli'}\n",
      "Optimizer: Adam\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/7500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 4/7500 [00:03<1:22:48,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 10/7500 [00:03<25:29,  4.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 16/7500 [00:03<13:07,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 22/7500 [00:04<08:37, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 28/7500 [00:04<06:39, 18.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 34/7500 [00:04<05:50, 21.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 37/7500 [00:04<05:31, 22.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 43/7500 [00:05<05:20, 23.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 49/7500 [00:05<05:05, 24.39it/s, kl_loss=0.332, loss=8.58e+3, rec_loss=8.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 55/7500 [00:05<04:59, 24.87it/s, kl_loss=0.332, loss=8.58e+3, rec_loss=8.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 61/7500 [00:05<04:58, 24.91it/s, kl_loss=0.332, loss=8.58e+3, rec_loss=8.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 67/7500 [00:05<04:54, 25.23it/s, kl_loss=0.332, loss=8.58e+3, rec_loss=8.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 73/7500 [00:06<04:57, 24.96it/s, kl_loss=0.332, loss=8.58e+3, rec_loss=8.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 79/7500 [00:06<04:57, 24.91it/s, kl_loss=0.332, loss=8.58e+3, rec_loss=8.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 82/7500 [00:06<05:01, 24.56it/s, kl_loss=0.332, loss=8.58e+3, rec_loss=8.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 88/7500 [00:06<05:15, 23.50it/s, kl_loss=0.332, loss=8.58e+3, rec_loss=8.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 94/7500 [00:07<05:15, 23.51it/s, kl_loss=0.332, loss=8.58e+3, rec_loss=8.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 97/7500 [00:07<05:22, 22.98it/s, kl_loss=0.332, loss=8.58e+3, rec_loss=8.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 103/7500 [00:07<05:27, 22.61it/s, kl_loss=0.000906, loss=8.18e+3, rec_loss=8.18e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 109/7500 [00:07<05:22, 22.89it/s, kl_loss=0.000906, loss=8.18e+3, rec_loss=8.18e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 115/7500 [00:08<05:11, 23.73it/s, kl_loss=0.000906, loss=8.18e+3, rec_loss=8.18e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 118/7500 [00:08<05:05, 24.16it/s, kl_loss=0.000906, loss=8.18e+3, rec_loss=8.18e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 124/7500 [00:08<04:57, 24.78it/s, kl_loss=0.000906, loss=8.18e+3, rec_loss=8.18e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 130/7500 [00:08<05:00, 24.53it/s, kl_loss=0.000906, loss=8.18e+3, rec_loss=8.18e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 136/7500 [00:08<05:02, 24.34it/s, kl_loss=0.000906, loss=8.18e+3, rec_loss=8.18e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 142/7500 [00:09<04:57, 24.75it/s, kl_loss=0.000906, loss=8.18e+3, rec_loss=8.18e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 148/7500 [00:09<05:00, 24.50it/s, kl_loss=0.000906, loss=8.18e+3, rec_loss=8.18e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 151/7500 [00:09<04:55, 24.89it/s, kl_loss=0.00605, loss=7.75e+3, rec_loss=7.75e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 157/7500 [00:09<05:04, 24.14it/s, kl_loss=0.00605, loss=7.75e+3, rec_loss=7.75e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 163/7500 [00:09<05:04, 24.06it/s, kl_loss=0.00605, loss=7.75e+3, rec_loss=7.75e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 169/7500 [00:10<04:57, 24.60it/s, kl_loss=0.00605, loss=7.75e+3, rec_loss=7.75e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 175/7500 [00:10<05:07, 23.82it/s, kl_loss=0.00605, loss=7.75e+3, rec_loss=7.75e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 178/7500 [00:10<05:08, 23.73it/s, kl_loss=0.00605, loss=7.75e+3, rec_loss=7.75e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 184/7500 [00:10<05:05, 23.97it/s, kl_loss=0.00605, loss=7.75e+3, rec_loss=7.75e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 190/7500 [00:11<05:06, 23.86it/s, kl_loss=0.00605, loss=7.75e+3, rec_loss=7.75e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 193/7500 [00:11<05:03, 24.08it/s, kl_loss=0.00605, loss=7.75e+3, rec_loss=7.75e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 199/7500 [00:11<05:02, 24.15it/s, kl_loss=0.00492, loss=7.62e+3, rec_loss=7.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 205/7500 [00:11<04:50, 25.07it/s, kl_loss=0.00492, loss=7.62e+3, rec_loss=7.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 211/7500 [00:11<04:38, 26.21it/s, kl_loss=0.00492, loss=7.62e+3, rec_loss=7.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 217/7500 [00:12<04:40, 25.96it/s, kl_loss=0.00492, loss=7.62e+3, rec_loss=7.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 223/7500 [00:12<04:42, 25.80it/s, kl_loss=0.00492, loss=7.62e+3, rec_loss=7.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 229/7500 [00:12<04:53, 24.77it/s, kl_loss=0.00492, loss=7.62e+3, rec_loss=7.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 232/7500 [00:12<04:57, 24.43it/s, kl_loss=0.00492, loss=7.62e+3, rec_loss=7.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 238/7500 [00:13<05:03, 23.93it/s, kl_loss=0.00492, loss=7.62e+3, rec_loss=7.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 241/7500 [00:13<05:06, 23.68it/s, kl_loss=0.00492, loss=7.62e+3, rec_loss=7.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 247/7500 [00:13<05:01, 24.07it/s, kl_loss=0.00492, loss=7.62e+3, rec_loss=7.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 253/7500 [00:13<04:54, 24.60it/s, kl_loss=0.00166, loss=7.57e+3, rec_loss=7.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 259/7500 [00:13<05:05, 23.72it/s, kl_loss=0.00166, loss=7.57e+3, rec_loss=7.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▎         | 265/7500 [00:14<04:59, 24.17it/s, kl_loss=0.00166, loss=7.57e+3, rec_loss=7.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▎         | 271/7500 [00:14<04:53, 24.66it/s, kl_loss=0.00166, loss=7.57e+3, rec_loss=7.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▎         | 277/7500 [00:14<04:53, 24.59it/s, kl_loss=0.00166, loss=7.57e+3, rec_loss=7.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▎         | 280/7500 [00:14<05:01, 23.95it/s, kl_loss=0.00166, loss=7.57e+3, rec_loss=7.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 286/7500 [00:15<05:06, 23.56it/s, kl_loss=0.00166, loss=7.57e+3, rec_loss=7.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 292/7500 [00:15<05:06, 23.49it/s, kl_loss=0.00166, loss=7.57e+3, rec_loss=7.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 298/7500 [00:15<04:59, 24.03it/s, kl_loss=0.00166, loss=7.57e+3, rec_loss=7.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 301/7500 [00:15<04:56, 24.25it/s, kl_loss=0.000899, loss=7.55e+3, rec_loss=7.55e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 307/7500 [00:15<04:51, 24.71it/s, kl_loss=0.000899, loss=7.55e+3, rec_loss=7.55e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 313/7500 [00:16<04:50, 24.77it/s, kl_loss=0.000899, loss=7.55e+3, rec_loss=7.55e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 319/7500 [00:16<04:43, 25.30it/s, kl_loss=0.000899, loss=7.55e+3, rec_loss=7.55e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 322/7500 [00:16<04:51, 24.62it/s, kl_loss=0.000899, loss=7.55e+3, rec_loss=7.55e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n",
      "samples_qzx shape: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m model_3dshapes, loss_fn_3dshapes, optimizer_3dshapes \u001b[38;5;241m=\u001b[39m setup_components(shapes3d_dataset, shapes3d_loss_kwargs)\n\u001b[1;32m      4\u001b[0m trainer_3dshapes \u001b[38;5;241m=\u001b[39m UnsupervisedTrainer(model\u001b[38;5;241m=\u001b[39mmodel_3dshapes,\n\u001b[1;32m      5\u001b[0m                                       loss_fn\u001b[38;5;241m=\u001b[39mloss_fn_3dshapes,\n\u001b[1;32m      6\u001b[0m                                       scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                       train_step_unit\u001b[38;5;241m=\u001b[39mtrain_step_unit,\n\u001b[1;32m     10\u001b[0m                                       )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer_3dshapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes3d_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_train_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/trainers/basetrainer.py:93\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self, data_loader, max_steps)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch\n\u001b[0;32m---> 93\u001b[0m     mean_epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# Assuming scheduler steps per epoch if epoch-based training\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/notebooks/trainers/basetrainer.py:165\u001b[0m, in \u001b[0;36mBaseTrainer._train_epoch\u001b[0;34m(self, data_loader, epoch)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data_out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):  \u001b[38;5;66;03m# Use enumerate to get iteration index 'i'\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     data \u001b[38;5;241m=\u001b[39m data_out[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 165\u001b[0m     iter_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, item \u001b[38;5;129;01min\u001b[39;00m iter_out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto_log\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    168\u001b[0m         epoch_to_log[key]\u001b[38;5;241m.\u001b[39mappend(item)\n",
      "File \u001b[0;32m/notebooks/trainers/basetrainer.py:205\u001b[0m, in \u001b[0;36mBaseTrainer._train_iteration\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    198\u001b[0m model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(samples)\n\u001b[1;32m    199\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: samples,\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_train\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_out,\n\u001b[1;32m    203\u001b[0m }\n\u001b[0;32m--> 205\u001b[0m loss_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/notebooks/losses/s_vae/beta_toroidal_vae.py:69\u001b[0m, in \u001b[0;36mBetaToroidalVAELoss.__call__\u001b[0;34m(self, data, reconstructions, stats_qzx, is_train, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 1. Calculate all values first\u001b[39;00m\n\u001b[1;32m     68\u001b[0m rec_loss \u001b[38;5;241m=\u001b[39m reconstruction_loss(data, reconstructions, distribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_dist)\n\u001b[0;32m---> 69\u001b[0m kl_components \u001b[38;5;241m=\u001b[39m \u001b[43mkl_power_spherical_uniform_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_factors_dist_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Returns shape (latent_factor_num,)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m kl_total \u001b[38;5;241m=\u001b[39m kl_components\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;66;03m# Scalar tensor\u001b[39;00m\n\u001b[1;32m     71\u001b[0m loss \u001b[38;5;241m=\u001b[39m rec_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m*\u001b[39m kl_total\n",
      "File \u001b[0;32m/notebooks/losses/s_vae/kl_div.py:54\u001b[0m, in \u001b[0;36mkl_power_spherical_uniform_loss\u001b[0;34m(latent_factors_dist_param, return_components)\u001b[0m\n\u001b[1;32m     51\u001b[0m     p_z \u001b[38;5;241m=\u001b[39m HypersphericalUniform(dim, device\u001b[38;5;241m=\u001b[39mmu\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# KL divergence per batch element for this factor, then averaged\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     kl_factor \u001b[38;5;241m=\u001b[39m \u001b[43mD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_divergence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_z_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_z\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     56\u001b[0m     kl_components\u001b[38;5;241m.\u001b[39mappend(kl_factor)\n\u001b[1;32m     58\u001b[0m kl_components_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(kl_components) \u001b[38;5;66;03m# Shape (latent_factor_num,)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributions/kl.py:191\u001b[0m, in \u001b[0;36mkl_divergence\u001b[0;34m(p, q)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo KL(p || q) is implemented for p type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and q type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     )\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/power_spherical/distributions.py:221\u001b[0m, in \u001b[0;36m_kl_powerspherical_uniform\u001b[0;34m(p, q)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;129m@register_kl\u001b[39m(PowerSpherical, HypersphericalUniform)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_kl_powerspherical_uniform\u001b[39m(p, q):\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mp\u001b[38;5;241m.\u001b[39mentropy() \u001b[38;5;241m+\u001b[39m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/power_spherical/distributions.py:81\u001b[0m, in \u001b[0;36mHypersphericalUniform.entropy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentropy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/power_spherical/distributions.py:72\u001b[0m, in \u001b[0;36mHypersphericalUniform.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlgamma\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Training on 3D Shapes =====\")\n",
    "model_3dshapes, loss_fn_3dshapes, optimizer_3dshapes = setup_components(shapes3d_dataset, shapes3d_loss_kwargs)\n",
    "\n",
    "trainer_3dshapes = UnsupervisedTrainer(model=model_3dshapes,\n",
    "                                      loss_fn=loss_fn_3dshapes,\n",
    "                                      scheduler=None,\n",
    "                                      optimizer=optimizer_3dshapes,\n",
    "                                      device=device,\n",
    "                                      train_step_unit=train_step_unit,\n",
    "                                      )\n",
    "\n",
    "trainer_3dshapes.train(shapes3d_dataloader, num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a1bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
