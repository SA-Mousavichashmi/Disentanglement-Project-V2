{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f68db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils.visualize\n",
    "from trainers import UnsupervisedTrainer\n",
    "import losses\n",
    "import vae_models\n",
    "from datasets import get_dataset\n",
    "from utils.io import find_optimal_num_workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d8255",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab80ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- General Hyperparameters ---\n",
    "model_name = 'toroidal_vae_burgess'  # Name of the model architecture file (e.g., 'vae_burgess')\n",
    "latent_factor_num = 10\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "rec_dist = 'bernoulli'  # Reconstruction distribution (e.g., 'bernoulli', 'gaussian')\n",
    "\n",
    "# train_step_unit = 'iteration'  # Unit for training steps ('epoch' or 'iteration')\n",
    "# num_train_steps = int(3e5)  # Number of training steps \n",
    "\n",
    "train_step_unit = 'epoch'  # Unit for training steps ('epoch' or 'iteration')\n",
    "num_train_steps = 5  # Number of training steps (epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0cce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss Specific Hyperparameters ---\n",
    "# Beta VAE\n",
    "loss_name = 'beta_toroidal_vae' \n",
    "loss_kwargs = {\n",
    "    'beta': 16,\n",
    "    'rec_dist': rec_dist\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572dfd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AnnealedVAE\n",
    "# loss_name = 'annealedvae'  \n",
    "# loss_kwargs = {\n",
    "#     'C_init': 0.0,\n",
    "#     'C_fin_3dshapes': 25.0,\n",
    "#     'C_fin_dsprites': 15.0,\n",
    "#     'gamma_annealed': 100.0,\n",
    "#     'anneal_steps': 10000,\n",
    "#     'rec_dist': rec_dist,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BetaTCVAE\n",
    "# loss_name = 'betatcvae'\n",
    "# loss_kwargs = {\n",
    "#     'alpha_tc': 1.0,\n",
    "#     'beta_tc_3dshapes': 6.0,\n",
    "#     'beta_tc_dsprites': 4.0,\n",
    "#     'gamma_tc': 1.0,\n",
    "#     'is_mss': True,\n",
    "#     'rec_dist': rec_dist\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272979c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Factor VAE\n",
    "\n",
    "# loss_name = 'factorvae'\n",
    "# loss_kwargs = {\n",
    "#     'device': device,\n",
    "#     'gamma': 6.4,\n",
    "#     'discr_lr': 5e-5,\n",
    "#     'discr_betas': (0.5, 0.9),\n",
    "#     'rec_dist': rec_dist,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e053bc",
   "metadata": {},
   "source": [
    "## 3. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2942d0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3D Shapes dataset with 480000 samples.\n",
      "Loaded dSprites dataset with 737280 samples.\n"
     ]
    }
   ],
   "source": [
    "# Load 3D Shapes\n",
    "Shapes3D = get_dataset(\"shapes3d\")\n",
    "shapes3d_dataset = Shapes3D(selected_factors='all', not_selected_factors_index_value=None)\n",
    "# num_workers_3dshapes = find_optimal_num_workers(shapes3d_dataset, batch_size=batch_size, num_batches_to_test='all')\n",
    "num_workers_3dshapes = 4\n",
    "\n",
    "shapes3d_dataloader = torch.utils.data.DataLoader(shapes3d_dataset, batch_size=batch_size, num_workers=num_workers_3dshapes, shuffle=True, pin_memory=True)\n",
    "print(f\"Loaded 3D Shapes dataset with {len(shapes3d_dataset)} samples.\")\n",
    "\n",
    "# Load dSprites\n",
    "Dsprites = get_dataset('dsprites')\n",
    "\n",
    "dsprites_dataset = Dsprites(selected_factors='all', not_selected_factors_index_value=None)\n",
    "# num_workers_dsprites = find_optimal_num_workers(dsprites_dataset, batch_size=batch_size, num_batches_to_test='all')\n",
    "num_workers_dsprites = 7\n",
    "\n",
    "dsprites_dataloader = torch.utils.data.DataLoader(dsprites_dataset, batch_size=batch_size, num_workers=num_workers_dsprites, shuffle=True, pin_memory=True)\n",
    "print(f\"Loaded dSprites dataset with {len(dsprites_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ad3aa",
   "metadata": {},
   "source": [
    "## 4. Setup Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57116ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_components(dataset, loss_kwargs):\n",
    "    \"\"\"Instantiates model, loss function, and optimizer based on config.\"\"\"\n",
    "    img_size = dataset[0][0].shape\n",
    "    n_data = len(dataset)\n",
    "    \n",
    "\n",
    "    # Instantiate Model\n",
    "    model = vae_models.select(name=model_name, img_size=img_size, latent_factor_num=latent_factor_num)\n",
    "\n",
    "    if loss_name == 'betatcvae':\n",
    "        loss_kwargs['n_data'] = n_data\n",
    "    \n",
    "    loss_fn = losses.select(loss_name, **loss_kwargs)\n",
    "\n",
    "    # Instantiate Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"--- Setup for {dataset.__class__.__name__} --- \")\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Loss: {loss_fn.__class__.__name__} (rec_dist={rec_dist}), kwargs={loss_kwargs}\")\n",
    "    print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "    print(f\"---------------------------\")\n",
    "\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354ebcb",
   "metadata": {},
   "source": [
    "## 5. Train and Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae44524",
   "metadata": {},
   "source": [
    "## 5.1 - 3D Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "017cfdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes3d_loss_kwargs =  {\n",
    "     'beta': 16,\n",
    "     'rec_dist': rec_dist\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03c610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training on 3D Shapes =====\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'kl_toroidal_loss' from 'losses.s_vae.kl_div' (/notebooks/losses/s_vae/kl_div.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m===== Training on 3D Shapes =====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model_3dshapes, loss_fn_3dshapes, optimizer_3dshapes \u001b[38;5;241m=\u001b[39m \u001b[43msetup_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes3d_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapes3d_loss_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m trainer_3dshapes \u001b[38;5;241m=\u001b[39m UnsupervisedTrainer(model\u001b[38;5;241m=\u001b[39mmodel_3dshapes,\n\u001b[1;32m      5\u001b[0m                                       loss_fn\u001b[38;5;241m=\u001b[39mloss_fn_3dshapes,\n\u001b[1;32m      6\u001b[0m                                       scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                       train_step_unit\u001b[38;5;241m=\u001b[39mtrain_step_unit,\n\u001b[1;32m     10\u001b[0m                                       )\n\u001b[1;32m     12\u001b[0m trainer_3dshapes\u001b[38;5;241m.\u001b[39mtrain(shapes3d_dataloader, num_train_steps)\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36msetup_components\u001b[0;34m(dataset, loss_kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetatcvae\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     11\u001b[0m     loss_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_data\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m n_data\n\u001b[0;32m---> 13\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m \u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloss_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Instantiate Optimizer\u001b[39;00m\n\u001b[1;32m     16\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n",
      "File \u001b[0;32m/notebooks/losses/__init__.py:39\u001b[0m, in \u001b[0;36mselect\u001b[0;34m(name, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Loss(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta_toroidal_vae\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ms_vae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeta_toroidal_vae\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BetaToroidalVAELoss\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BetaToroidalVAELoss(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     42\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown loss.name = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Possible values: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/notebooks/losses/s_vae/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeta_toroidal_vae\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BetaToroidalVAELoss\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBetaToroidalVAELoss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m ]\n",
      "File \u001b[0;32m/notebooks/losses/s_vae/beta_toroidal_vae.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m baseloss\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreconstruction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reconstruction_loss\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkl_div\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kl_toroidal_loss\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBetaToroidalVAELoss\u001b[39;00m(baseloss\u001b[38;5;241m.\u001b[39mBaseLoss):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Compute the Beta-Toroidal-VAE loss. This is similar to Beta-VAE but uses\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    the KL divergence for the Power Spherical distribution against a uniform prior on S^1.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m        Additional arguments for `BaseLoss`, e.g., `rec_dist`.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'kl_toroidal_loss' from 'losses.s_vae.kl_div' (/notebooks/losses/s_vae/kl_div.py)"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Training on 3D Shapes =====\")\n",
    "model_3dshapes, loss_fn_3dshapes, optimizer_3dshapes = setup_components(shapes3d_dataset, shapes3d_loss_kwargs)\n",
    "\n",
    "trainer_3dshapes = UnsupervisedTrainer(model=model_3dshapes,\n",
    "                                      loss_fn=loss_fn_3dshapes,\n",
    "                                      scheduler=None,\n",
    "                                      optimizer=optimizer_3dshapes,\n",
    "                                      device=device,\n",
    "                                      train_step_unit=train_step_unit,\n",
    "                                      )\n",
    "\n",
    "trainer_3dshapes.train(shapes3d_dataloader, num_train_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
