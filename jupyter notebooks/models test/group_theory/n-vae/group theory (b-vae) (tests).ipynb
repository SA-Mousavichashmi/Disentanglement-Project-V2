{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faeffa99",
   "metadata": {},
   "source": [
    "# VAE Model Testing Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root by looking for .git or requirements.txt\n",
    "current = Path.cwd()\n",
    "while not any((current / marker).exists() for marker in ['.git', 'requirements.txt']):\n",
    "    if current.parent == current:\n",
    "        raise FileNotFoundError(\"Project root not found\")\n",
    "    current = current.parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "print(f\"Added project root: {current}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a01f25b",
   "metadata": {},
   "source": [
    "# Hyperparemeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#### deterministic run ####\n",
    "determinism_kwargs = {\n",
    "    'seed':0,\n",
    "    'use_cuda_det': True,\n",
    "    'enforce_det':False,\n",
    "    'cublas_workspace_config': None,\n",
    "}\n",
    "##### Model parameters #####\n",
    "model_name = 'vae_locatello'  # Name of the model architecture file (e.g., 'vae_burgess')\n",
    "model_decoder_output_dist = 'bernoulli'  # Output distribution of the decoder (e.g., 'bernoulli', 'gaussian')\n",
    "latent_dim = 10\n",
    "use_torch_compile = True  # Use torch.compile for model compilation (requires PyTorch 2.0 or higher)\n",
    "\n",
    "#### Training parameters ####\n",
    "train_step_unit = 'epoch'  # Unit for training steps ('epoch' or 'iteration')\n",
    "num_train_steps = 1\n",
    "\n",
    "# train_step_unit = 'iteration'  # Unit for training steps ('epoch' or 'iteration')\n",
    "# num_train_steps = int(9e3)  # Number of training steps \n",
    "\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "\n",
    "#### device parameters ####\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "\n",
    "# --- Loss Specific Hyperparameters ---\n",
    "loss_name = 'group_theory'\n",
    "base_loss_name = 'betavae'\n",
    "\n",
    "group_loss_kwargs = {\n",
    "    'base_loss_name': base_loss_name,\n",
    "    'base_loss_kwargs': {\n",
    "        'rec_dist': 'gaussian',\n",
    "        'latent_dim': latent_dim,\n",
    "        'beta': 16, # Default beta\n",
    "        'log_kl_components': True\n",
    "    },\n",
    "    'rec_dist': 'gaussian',\n",
    "    'device': device,\n",
    "    'commutative_comparison_dist': 'gaussian',\n",
    "    'commutative_weight': 1.0,\n",
    "    'meaningful_weight': 1.0,\n",
    "    'commutative_component_order': 2,\n",
    "    'meaningful_component_order': 1,\n",
    "    'meaningful_transformation_order': 1,\n",
    "    'meaningful_critic_gradient_penalty_weight': 10,\n",
    "    'meaningful_critic_lr': 1e-4,\n",
    "    'meaningful_n_critic': 10,\n",
    "    'deterministic_rep': False\n",
    "}\n",
    "\n",
    "### Checkpoint parameters ###\n",
    "return_chkpt = False\n",
    "chkpt_every_n_steps=None\n",
    "\n",
    "# chkpt_save_path = 'checkpoints/tests/test-epoch-1.pt'\n",
    "chkpt_save_path = None\n",
    "\n",
    "chkpt_save_dir = None\n",
    "chkpt_save_master_dir=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486cf8a9",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if determinism_kwargs is not None:\n",
    "    # MUST Be set before importing any other modules\n",
    "    # to ensure reproducibility across all libraries\n",
    "    from utils.reproducibility import set_deterministic_run, get_deterministic_dataloader\n",
    "    set_deterministic_run(**determinism_kwargs)\n",
    "    print(f\"Set deterministic run with kwargs: {determinism_kwargs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a4f2e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils.visualize\n",
    "from trainers import UnsupervisedTrainer\n",
    "import losses\n",
    "import vae_models\n",
    "from datasets import get_dataset\n",
    "from utils.io import find_optimal_num_workers\n",
    "from metrics.utils import MetricAggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd6489",
   "metadata": {},
   "source": [
    "# Shapes3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36a9b4",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b96671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 3D Shapes\n",
    "Shapes3D = get_dataset(\"shapes3d\")\n",
    "shapes3d_dataset = Shapes3D(selected_factors='all', not_selected_factors_index_value=None)\n",
    "\n",
    "# num_workers_3dshapes = find_optimal_num_workers(shapes3d_dataset, batch_size=batch_size, num_batches_to_test='all')\n",
    "num_workers_3dshapes = 4\n",
    "\n",
    "if determinism_kwargs is not None:\n",
    "    shapes3d_dataloader = get_deterministic_dataloader(dataset=shapes3d_dataset, \n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers_3dshapes,\n",
    "                                                   seed=determinism_kwargs['seed'],\n",
    "                                                   pin_memory=True)\n",
    "else:\n",
    "    shapes3d_dataloader = torch.utils.data.DataLoader(shapes3d_dataset, \n",
    "                                                      batch_size=batch_size, \n",
    "                                                      num_workers=num_workers_3dshapes, \n",
    "                                                      shuffle=True, \n",
    "                                                      pin_memory=True)\n",
    "\n",
    "\n",
    "print(f\"Loaded 3D Shapes dataset with {len(shapes3d_dataset)} samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd49037",
   "metadata": {},
   "source": [
    "## Setup Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3621be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_components(dataset, loss_kwargs):\n",
    "    \"\"\"Instantiates model, loss function, and optimizer based on config.\"\"\"\n",
    "    img_size = dataset[0][0].shape\n",
    "    n_data = len(dataset)\n",
    "    \n",
    "\n",
    "    # Instantiate Model\n",
    "    model = vae_models.select(name=model_name, \n",
    "                              img_size=img_size, \n",
    "                              latent_dim=latent_dim, \n",
    "                              decoder_output_dist=model_decoder_output_dist\n",
    "                              ).to(device)\n",
    "\n",
    "    if loss_name == 'betatcvae':\n",
    "        loss_kwargs['n_data'] = n_data\n",
    "    \n",
    "    loss_fn = losses.select(loss_name, **loss_kwargs)\n",
    "\n",
    "    # Instantiate Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"--- Setup for {dataset.__class__.__name__} --- \")\n",
    "    print(f\"Model: {model.model_name}\")\n",
    "    print(f\"Loss: {loss_fn.name} (rec_dist={loss_kwargs['rec_dist']}), kwargs={loss_kwargs}\")\n",
    "    print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "    print(f\"---------------------------\")\n",
    "\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aae795",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89feb089",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes3d_loss_kwargs = group_loss_kwargs.copy()\n",
    "shapes3d_loss_kwargs.update({'beta': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b164af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Training on 3D Shapes =====\")\n",
    "model_3dshapes, loss_fn_3dshapes, optimizer_3dshapes = setup_components(shapes3d_dataset, shapes3d_loss_kwargs)\n",
    "\n",
    "trainer_3dshapes = UnsupervisedTrainer(model=model_3dshapes,\n",
    "                                      loss=loss_fn_3dshapes,\n",
    "                                      optimizer=optimizer_3dshapes,\n",
    "                                      lr_scheduler=None,\n",
    "                                      determinism_kwargs=determinism_kwargs,\n",
    "                                      use_torch_compile=use_torch_compile,\n",
    "                                      return_log_loss=True,\n",
    "                                      return_chkpt=return_chkpt,\n",
    "                                      chkpt_save_path=chkpt_save_path,\n",
    "                                      )\n",
    "\n",
    "trainer_3dshapes.train(step_unit=train_step_unit, max_steps=num_train_steps, dataloader=shapes3d_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84438eca",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer_3dshapes = utils.visualize.Visualizer(vae_model=model_3dshapes, dataset=shapes3d_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79527902",
   "metadata": {},
   "source": [
    "#### Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da151c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting random reconstructions...\")\n",
    "visualizer_3dshapes.plot_random_reconstructions(10, mode='mean')\n",
    "plt.show()\n",
    "\n",
    "print(\"Plotting reconstructions from specific indices...\")\n",
    "indices_3dshapes = [5000, 6000, 7000, 100, 1000, 1024] # Example indices\n",
    "visualizer_3dshapes.plot_reconstructions_sub_dataset(indices_3dshapes, mode='mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21a961f",
   "metadata": {},
   "source": [
    "#### Latent traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d592e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting latent traversals...\")\n",
    "visualizer_3dshapes.plot_all_latent_traversals(num_samples=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d209c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img_idx = 1000\n",
    "ref_img = shapes3d_dataset[ref_img_idx][0]\n",
    "plt.imshow(ref_img.permute(1, 2, 0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb236bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single latent traversal based on the reference image\n",
    "latent_idx = 0  # Index of the latent dimension to traverse\n",
    "visualizer_3dshapes.plot_single_latent_traversal(latent_idx, \n",
    "                                                 ref_img=ref_img, \n",
    "                                                 num_samples=5,\n",
    "                                                 max_traversal_type='absolute', \n",
    "                                                 max_traversal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer_3dshapes.plot_all_latent_traversals(ref_img=ref_img, \n",
    "                                               num_samples=25,  \n",
    "                                               max_traversal_type='probability',\n",
    "                                               max_traversal=0.95,\n",
    "                                               use_ref_img_lat_std=False\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3f3b1",
   "metadata": {},
   "source": [
    "## Metric Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a433297",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_compute = [\n",
    "    {'name': 'dci_d', 'args':{'num_train':5000, 'num_test':1000}}, # Added num_train and num_test\n",
    "    {'name': 'mig', 'args':{}} # MIG uses default args (num_bins=20, num_workers=8, etc.)\n",
    "]\n",
    "\n",
    "metric_aggregator_3dshapes = MetricAggregator(metrics=metrics_to_compute)\n",
    "\n",
    "print(\"\\n===== Computing Metrics for 3D Shapes =====\")\n",
    "metrics_results_3dshapes = metric_aggregator_3dshapes.compute(model=model_3dshapes, \n",
    "                                                              data_loader=shapes3d_dataloader, \n",
    "                                                              device=device)\n",
    "print(\"3D Shapes Metrics:\", metrics_results_3dshapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820acfd4",
   "metadata": {},
   "source": [
    "# dSprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dSprites\n",
    "Dsprites = get_dataset('dsprites')\n",
    "\n",
    "dsprites_dataset = Dsprites(selected_factors='all', not_selected_factors_index_value=None)\n",
    "# num_workers_dsprites = find_optimal_num_workers(dsprites_dataset, batch_size=batch_size, num_batches_to_test='all')\n",
    "num_workers_dsprites = 7\n",
    "\n",
    "if determinism_kwargs is not None:\n",
    "    dsprites_dataloader = get_deterministic_dataloader(dataset=dsprites_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers_dsprites,\n",
    "                                                   seed=determinism_kwargs['seed'],\n",
    "                                                   pin_memory=True)\n",
    "else:\n",
    "    dsprites_dataloader = torch.utils.data.DataLoader(dsprites_dataset, \n",
    "                                                      batch_size=batch_size, \n",
    "                                                      num_workers=num_workers_dsprites, \n",
    "                                                      shuffle=True, \n",
    "                                                      pin_memory=True)\n",
    "\n",
    "print(f\"Loaded dSprites dataset with {len(dsprites_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0fc328",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0752d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta VAE\n",
    "loss_kwargs_beta_vae_dsprites =  {\n",
    "    'beta': 16,\n",
    "    'rec_dist': 'bernoulli', # Use the globally defined rec_dist\n",
    "    'log_kl_components':True\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Training on dSprites =====\")\n",
    "model_dsprites, loss_fn_dsprites, optimizer_dsprites = setup_components(dsprites_dataset, loss_kwargs_beta_vae_dsprites)\n",
    "\n",
    "trainer_dsprites = UnsupervisedTrainer(model=model_dsprites,\n",
    "                                      loss=loss_fn_dsprites,\n",
    "                                      optimizer=optimizer_dsprites,\n",
    "                                      lr_scheduler=None,\n",
    "                                      determinism_kwargs=determinism_kwargs,\n",
    "                                      use_torch_compile=use_torch_compile,\n",
    "                                      return_log_loss=True,\n",
    "                                      return_chkpt=return_chkpt,\n",
    "                                      chkpt_save_path=chkpt_save_path,\n",
    "                                      )\n",
    "trainer_dsprites.train(max_steps=num_train_steps, step_unit=train_step_unit, dataloader=dsprites_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a16b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Visualizing dSprites Results =====\")\n",
    "visualizer_dsprites = utils.visualize.Visualizer(vae_model=model_dsprites, dataset=dsprites_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c01034",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1fc4c",
   "metadata": {},
   "source": [
    "### Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting random reconstructions...\")\n",
    "visualizer_dsprites.plot_random_reconstructions(10, mode='mean')\n",
    "plt.show()\n",
    "\n",
    "print(\"Plotting reconstructions from specific indices...\")\n",
    "indices_dsprites = [0, 100000, 200000, 300000, 40000, 50000] # Example indices\n",
    "visualizer_dsprites.plot_reconstructions_sub_dataset(indices_dsprites, mode='mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd9315",
   "metadata": {},
   "source": [
    "### Latent traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da894d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting latent traversals...\")\n",
    "visualizer_dsprites.plot_all_latent_traversals(num_samples=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d175f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a reference image index for dSprites\n",
    "ref_img_idx_dsprites = 10000  # Example index\n",
    "ref_img_dsprites = dsprites_dataset[ref_img_idx_dsprites][0]\n",
    "\n",
    "# Plot the reference image\n",
    "plt.imshow(ref_img_dsprites.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
    "plt.title(f\"dSprites Reference Image (Index: {ref_img_idx_dsprites})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10efa056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single latent traversal based on the reference image\n",
    "latent_idx_dsprites = 0  # Index of the latent dimension to traverse\n",
    "print(f\"Plotting single latent traversal for dimension {latent_idx_dsprites}...\")\n",
    "visualizer_dsprites.plot_single_latent_traversal(latent_idx_dsprites, ref_img=ref_img_dsprites, num_samples=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All latent traversals based on the reference image\n",
    "print(\"Plotting all latent traversals based on reference image...\")\n",
    "visualizer_dsprites.plot_all_latent_traversals(ref_img=ref_img_dsprites, num_samples=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181e8d0",
   "metadata": {},
   "source": [
    "## Metric Evaluation (dSprites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2434669",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Computing Metrics for dSprites =====\")\n",
    "metric_aggregator_dsprites = MetricAggregator(metrics=metrics_to_compute)\n",
    "\n",
    "metrics_results_dsprites = metric_aggregator_dsprites.compute(model=model_dsprites, \n",
    "                                                            data_loader=dsprites_dataloader, \n",
    "                                                            device=device)\n",
    "print(\"dSprites Metrics:\", metrics_results_dsprites)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
