{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "266610fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root: /notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root by looking for .git or requirements.txt\n",
    "current = Path.cwd()\n",
    "while not any((current / marker).exists() for marker in ['.git', 'requirements.txt']):\n",
    "    if current.parent == current:\n",
    "        raise FileNotFoundError(\"Project root not found\")\n",
    "    current = current.parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "print(f\"Added project root: {current}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b82d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import load_chkpt\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils.visualize\n",
    "from trainers.basetrainer import BaseTrainer, create_trainer_from_chkpt\n",
    "import losses\n",
    "import vae_models\n",
    "from datasets import get_dataset\n",
    "from utils.io import find_optimal_num_workers\n",
    "from metrics.utils import MetricAggregator\n",
    "from utils.io import print_chkpt_info\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf916f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from checkpoints/tests/test-epoch-1.pt on cuda\n"
     ]
    }
   ],
   "source": [
    "chkpt_test = load_chkpt('checkpoints/tests/test-epoch-1.pt', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6955f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_id', 'train_step_unit', 'train_step_num', 'train_seed', 'train_determinism_type', 'use_torch_compile', 'model', 'loss', 'optimizer', 'lr_scheduler', 'dataset', 'dataloader', 'metrics'])\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chkpt_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "418d95fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Information:\n",
      "  Train ID: fa9a7fdb-ff47-4458-b630-9d96595ae66e\n",
      "  Train Step Unit: epoch\n",
      "  Train Step Number: 1\n",
      "  Train Seed: 0\n",
      "  Train Determinism Type: full\n",
      "  Use Torch Compile: False\n",
      "#### Model ####\n",
      "  Model Name: vae_locatello\n",
      "  Model kwargs: {'img_size': torch.Size([3, 64, 64]), 'latent_dim': 10, 'encoder_decay': 0.0, 'decoder_decay': 0.0, 'decoder_output_dist': 'bernoulli'}\n",
      "#### Loss ####\n",
      "  Loss Name: betavae\n",
      "  Loss kwargs: {'beta': 16, 'log_kl_components': True, 'rec_dist': 'gaussian'}\n",
      "#### Dataset ####\n",
      "  Dataset Name: shapes3d\n",
      "  Dataset kwargs: {'selected_factors': 'all', 'not_selected_factors_index_value': None, 'root': 'data/shapes3d/', 'subset': 1}\n",
      "#### Dataloader ####\n",
      "  Dataloader kwargs: {'batch_size': 64, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'seed': 0, 'persistent_workers': True, 'in_order': True, 'snapshot_every_n_steps': 1}\n",
      "#### Optimizer ####\n",
      "  Optimizer Name: Adam\n",
      "  LR Scheduler Name: ConstantLR\n"
     ]
    }
   ],
   "source": [
    "print_chkpt_info(chkpt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37885382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_snapshot': {'_snapshot_step': 7500,\n",
       "  '_last_yielded_worker_id': 3,\n",
       "  '_main_snapshot': {'_num_workers': 4,\n",
       "   '_sampler_iter_state': {'samples_yielded': 480000,\n",
       "    'sampler_iter_state': {'yielded': 480000,\n",
       "     'generator': tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0', dtype=torch.uint8)}},\n",
       "   '_index_sampler_state': None,\n",
       "   '_sampler_iter_yielded': 7500,\n",
       "   '_IterableDataset_len_called': None,\n",
       "   '_shared_seed': None,\n",
       "   '_base_seed': 1559385941720436641},\n",
       "  '_worker_snapshots': {'worker_0': {'worker_id': 0,\n",
       "    'dataset_state': None,\n",
       "    'fetcher_state': None},\n",
       "   'worker_1': {'worker_id': 1, 'dataset_state': None, 'fetcher_state': None},\n",
       "   'worker_2': {'worker_id': 2, 'dataset_state': None, 'fetcher_state': None},\n",
       "   'worker_3': {'worker_id': 3,\n",
       "    'dataset_state': None,\n",
       "    'fetcher_state': None}}},\n",
       " '_steps_since_snapshot': 0,\n",
       " '_iterator_finished': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt_test['dataloader']['state_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e7538a",
   "metadata": {},
   "source": [
    "# Training tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29cc2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = create_trainer_from_chkpt(chkpt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789db215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RNG state must be a torch.ByteTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/trainers/basetrainer.py:243\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self, max_steps, dataloader)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# _train_epoch returns dict if log_loss_interval_type=='epoch', list if 'iteration'\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m epoch_logs_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_log_loss:\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_loss_interval_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;66;03m# epoch_logs_out already includes 'epoch' key from _train_epoch\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/trainers/basetrainer.py:409\u001b[0m, in \u001b[0;36mBaseTrainer._train_epoch\u001b[0;34m(self, data_loader, epoch)\u001b[0m\n\u001b[1;32m    404\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    405\u001b[0m               leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    406\u001b[0m               disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_progress_bar)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trange(num_batches, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data_out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    410\u001b[0m         data \u001b[38;5;241m=\u001b[39m data_out[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    411\u001b[0m         iter_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_iteration(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdata/stateful_dataloader/stateful_dataloader.py:402\u001b[0m, in \u001b[0;36mStatefulDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersistent_workers \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\u001b[38;5;241m.\u001b[39m_reset(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdata/stateful_dataloader/stateful_dataloader.py:387\u001b[0m, in \u001b[0;36mStatefulDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[43m_StatefulMultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_iter_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_iter_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m it\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdata/stateful_dataloader/stateful_dataloader.py:1053\u001b[0m, in \u001b[0;36m_StatefulMultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader, next_iter_state)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# Try to restore main state\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_iter_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1053\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_main_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_iter_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_SNAPSHOT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_MAIN_SNAPSHOT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m=\u001b[39m next_iter_state[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_SNAPSHOT][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_SNAPSHOT_STEP]\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_snapshot(\n\u001b[1;32m   1057\u001b[0m         snapshot_step\u001b[38;5;241m=\u001b[39mnext_iter_state[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_SNAPSHOT][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_SNAPSHOT_STEP],\n\u001b[1;32m   1058\u001b[0m         last_yielded_worker_id\u001b[38;5;241m=\u001b[39mnext_iter_state[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_SNAPSHOT][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_LAST_YIELDED_WORKER_ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         worker_snapshots\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_snapshots,\n\u001b[1;32m   1062\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdata/stateful_dataloader/stateful_dataloader.py:1477\u001b[0m, in \u001b[0;36m_StatefulMultiProcessingDataLoaderIter._restore_main_state\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_sampler)\n\u001b[1;32m   1476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state_dict[_SAMPLER_ITER_STATE] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1477\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;241m=\u001b[39m \u001b[43mtry_to_deserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_SAMPLER_ITER_STATE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_sampler,\n\u001b[1;32m   1481\u001b[0m         torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdataloader\u001b[38;5;241m.\u001b[39m_InfiniteConstantSampler,\n\u001b[1;32m   1482\u001b[0m     ):\n\u001b[1;32m   1483\u001b[0m         \u001b[38;5;66;03m# Fallback to fastforward\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdata/stateful_dataloader/worker.py:57\u001b[0m, in \u001b[0;36mtry_to_deserialize\u001b[0;34m(obj, state_dict)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_to_deserialize\u001b[39m(obj: T, state_dict: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Stateful):\n\u001b[0;32m---> 57\u001b[0m         \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdata/stateful_dataloader/sampler.py:156\u001b[0m, in \u001b[0;36m_BatchSamplerIterator.load_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_SAMPLER_ITER_STATE \u001b[38;5;129;01min\u001b[39;00m state_dict:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler_iter, Stateful)\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler_iter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_SAMPLER_ITER_STATE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler, Stateful) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler_iter, Stateful)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler, _InfiniteConstantSampler\n\u001b[1;32m    160\u001b[0m ):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# We skip x samples if underlying sampler is not stateful\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples_yielded):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdata/stateful_dataloader/sampler.py:69\u001b[0m, in \u001b[0;36m_StatefulRandomSamplerIterator.load_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_yielded \u001b[38;5;241m=\u001b[39m state_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_YIELDED]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator_state \u001b[38;5;241m=\u001b[39m state_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_GENERATOR]\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_yielded \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_perm()  \u001b[38;5;66;03m# We want permutations from the latest generator state that's loaded\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: RNG state must be a torch.ByteTensor"
     ]
    }
   ],
   "source": [
    "trainer.train(max_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d815f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
